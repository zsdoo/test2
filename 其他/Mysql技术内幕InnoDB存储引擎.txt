#### dqb工作内容

```sql
10多套环境， 每个环境一主多从，用的腾讯云高可用方案。
按业务类型分为多个库

DBA工作内容：
1 ：
监控工具：zabbix
监控内容：
主机：cpu  内存 磁盘IO、网络
mysql : 缓冲池命中率，缓冲池大小，连接线程、表缓存、慢查询

2
数据迁移、环境部署、维护

3 
版本升级时的sql 审核与sql 执行：

4 
sql优化：
首先从系统本身优化：如内存缓冲和索引
然后从内存CPU等硬件优化
最后从数据库业务方面，分库分表

5
数据迁移、备份和恢复，数据处理(存储过程开发)。
故障告警处理
新技术的跟踪


职责汇总：
监控
安装和配置、规划和设计
sql审核上线
性能调优sql优化
数据迁移、备份和恢复，数据处理(存储过程开发)。
故障告警处理
新技术的跟踪
```

#### mysql 8.0新特性：

##### 1NoSql存储

Mysql从5.7 版本提供了NoSQL的存储功能,在8.0中这部分得到一些修改,不过这个在实际中用的极少

##### 2.隐藏索引

隐藏索引的特性对于性能调试非常有用,在8.0 中,索引可以被隐藏和显示,当一个索引隐藏时,他不会被查询优化器所使用

![img](https://img-blog.csdnimg.cn/20190730104257425.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5Nzg3MzY3,size_16,color_FFFFFF,t_70)

也就是说可以隐藏一个索引,然后观察对数据库的影响.如果性能下降,就说明这个索引是有效的,于是将其”恢复显示”即可;如果数据库性能看不出变化,说明这个索引是多于的,可以删掉了

隐藏一个索引的语法

ALTER TABLE t ALTER INDEX i INVISIBLE;

恢复显示该索引的语法是：

	ALTER TABLE t ALTER INDEX i VISIBLE;

当一个索引被隐藏时,我们可以从show index命令的输出汇总看出,该索引visible属性值为No

**注意:**当索引被隐藏时,他的内容仍然是和正常索引一样实时更新的,这个特性本身是专门为了优化调试而使用的,如果你长期隐藏一个索引,那还不如干掉,因为索引的存在会影响数据的插入\更新和删除功能

##### 3.设置持久化

MySQL 的设置可以在运行时通过 SET GLOBAL 命令来更改，但是这种更改只会临时生效，到下次启动时数据库又会从配置文件中读取。
MySQL 8 新增了 SET PERSIST 命令，例如：
SET PERSIST max_connections = 500;
MySQL 会将该命令的配置保存到数据目录下的 mysqld-auto.cnf 文件中，下次启动时会读取该文件，用其中的配置来覆盖缺省的配置文件。

##### 4.UTF-8 编码

从 MySQL 8 开始，数据库的缺省编码将改为 utf8mb4，这个编码包含了所有 emoji 字符。多少年来我们使用 MySQL 都要在编码方面小心翼翼，生怕忘了将缺省的 latin 改掉而出现乱码问题。从此以后就不用担心了。

##### 5.通用表表达式（Common Table Expressions）

复杂的查询会使用嵌入式表，例如：

SELECT t1.*, t2.* FROM
	 (SELECT col1 FROM table1) t1,
	 (SELECT col2 FROM table2) t2;
而有了 CTE，我们可以这样写：

	WITH
	 t1 AS (SELECT col1 FROM table1),
	 t2 AS (SELECT col2 FROM table2)
	SELECT t1.*, t2.* 
	FROM t1, t2;

这样看上去层次和区域都更加分明，改起来也更清晰的知道要改哪一部分。
这个特性在很多报表场景是很有用的，也是mysql优化的一个很重要特性。

##### 6 窗口函数（Window Functions）

MySQL 被吐槽最多的特性之一就是缺少 rank() 函数，当需要在查询当中实现排名时，必须手写 @ 变量。但是从 8.0 开始，MySQL 新增了一个叫窗口函数的概念，它可以用来实现若干新的查询方式。
窗口函数有点像是 SUM()、COUNT() 那样的集合函数，但它并不会将多行查询结果合并为一行，而是将结果放回多行当中。也就是说，窗口函数是不需要 GROUP BY 的。
假设我们有一张 “班级学生人数” 表：

如果要对班级人数从小到大进行排名，可以这样利用窗口函数：

说明：在这里创建了名为 w 的 window，规定它对 stu_count 字段进行排序，然后在 select 子句中对 w 执行 rank() 方法，将结果输出为 rank 字段。
这个特性也是Oracle11g有的一个新特性，在优化也是起着很重要的作用。
――――――――――――――――
版权声明：本文为CSDN博主「a...Z」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/qq_39787367/article/details/97760284



#### sql优化

看执行计划，

1、查各单条语句用到的条数，以小表驱动大表，分别在关键字段上加索引，可考虑复合索引，冗余后期可能需要的字段。

2、看是执行计划是否用到索引，explan extended select  ... from

会发现有的字段未用到索引。原因：1）varchar和time 因类型不一致发生了隐式转换；2）字符集和校对规则不统一发生了隐式转换等等。



#### 数据库备份脚本

```sql
#!bin/bash
#test to backup mysqldata

echo  "`date +%F` `date +%T` start"
now=`date +%Y%m%d`
back_dir="/data/mysql_backup/`echo $now | cut -c1-6`"

if [ ! -d ${back_dir} ]; then
	
	mkdir -p ${back_dir}
fi

for dbname in ecocrm_cust balance buss_interface ecocrm_so ecocrm_pt ecocrm_pc
do
/opt/mysql-5.7.26/bin/mysqldump -h10.46.5.210 -P3306 -uyygl -p'tietapassw0rd' --skip-opt -R -E --databases ${dbname} >${back_dir}/${dbname}_${now}.sql
done

echo "`date +%F` `date +%T` end"
echo "end"
```

#### 缓冲池设置

```sql

#缓冲池的配置参数：innodb_buffer_pool_size
show variables like 'innodb_buffer_pool_size';  -- 134217728  /1024 / 1024 =128M     536870912=512
show VARIABLES like 'innodb_buffer_pool_chunk_size';

# 单个缓冲池实例
SELECT @@innodb_buffer_pool_instances;
SELECT @@innodb_buffer_pool_size/1024/1024/1024;

#当增加或减少innodb_buffer_pool_size时，该操作按照数据块(chunks)执行。数据块的大小通过innodb_buffer_pool_chunk_size配置选项进行定义，该选项默认为128M.
缓冲池大小必须总是等于innodb_buffer_pool_chunk_size* innodb_buffer_pool_instances或为其倍数。如果将innodb_buffer_pool_size配置为不等于innodb_buffer_pool_chunk_size *

#在线调整InnoDB缓冲池大小
innodb_buffer_pool_size配置选项能通过set语句进行动态设置，既允许用户不重启服务器的前提下调整缓冲大小。例如：
SET GLOBAL innodb_buffer_pool_size=536870912;


#监视在线缓冲调整进程
Innodb_buffer_pool_resize_status报告缓冲池调整进程。例如：
SHOW STATUS WHERE Variable_name='InnoDB_buffer_pool_resize_status';

#在线调整缓冲池内部机制
缓冲池的调整操作被后台线程执行。增加缓冲池大小时，调整操作：

1)增加数据块中的页(数据块大小由innodb_buffer_pool_chunk_size定义)

2)暗中使(covert)哈希表(hash tables),链表(lists)和指针(pointers)以使用内存中的新地址

3)将新页加到空闲链表上

当这些操作进行时，其他访问缓冲池的线程被阻塞。

当减少缓冲池大小时，调整操作：

1)整合缓冲区并释放页

2)移去数据块中的页(数据块大小由innodb_buffer_pool_chunk_size定义)

3)使哈希表(hash tbales)，链表(lists)和指针(pointers)使用内存中的新地址

这些操作中，仅整理缓冲池和释放页允许其他线程并发的访问该缓冲池。
――――――――――――――――
版权声明：本文为CSDN博主「写手一条城」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/weixin_32244597/article/details/113632095
```

#### tmp_table_size 临时表的内存缓存大小

- 临时表是指sql执行时生成临时数据表

  ```
    # tmp_table_size
    默认值 16777216
    最小值 1
    最大值 18446744073709551615
    // 单位字节 默认值也就是16M多
  12345
  ```

- 查看 tmp_table_size
  show global variables like ‘tmp_table_size’;

- 设置 tmp_table_size
  set global tmp_table_size= 2048; （立即生效重启后失效）

- MySQL 配置文件 my.cnf 中 mysqld 下添加 tmp_table_size
  [mysqld]
  tmp_table_size = 100000000

注意

MySQL中的 **max_heap_table_size** 参数会影响到临时表的内存缓存大小 。
max_heap_table_size 是MEMORY内存引擎的表大小 ， 因为临时表也是属于内存表所以也会受此参数的限制 所以如果要增加 tmp_table_size 的大小 也需要同时增加 max_heap_table_size 的大小
可以通过 Created_tmp_disk_tables 和 Created_tmp_tables 状态来分析是否需要增加 tmp_table_size

```
查看状态
show global status like 'Created_tmp_disk_tables';
show global status like 'Created_tmp_tables';

Created_tmp_disk_tables : 磁盘临时表的数量
Created_tmp_tables      : 内存临时表的数量
```



## 第一章 Mysql 体系结构和存储引擎

### 1.1 定义数据库和实例

**数据库：**物理操作系统文件或其他形式文件类型的集合。
**实例：**Mysql数据库由后台线程以及一个共享内存区组成。共享内存可以被运行的后台线程所共享。
数据库是文件的集合，是依照某种数据模型组织起来并存放于二级存储器中的数据集合。
数据库实例是程序，是位于用户与操作系统之间的一层数据管理软件，应用程序只有通过数据库实例才能和数据库打交道。

启动时，mysql数据库会读取配置文件，根据参数来启动数据库实例。如果没有配置文件，会按照编译时的默认参数设置启动实例。
查找配置文件：mysql --help | grep my.cnf
/etc/my.cnf --> /etc/mysql/my.cnf --> /usr/local/mysql/etc/my.cnf --> ~/.my.cnf
依次查找，以读取到的最后一个配置文件中的参数为准
与oracle类似，不同的是，oracle没有参数文件会启动失败。
配置文件中有一个参数datadir，该参数指定了数据库所在的路径。Linux默认为/usr/local/mysql/data
可用命令查看：Mysql> show variables like ‘datadir’\G

System ls-lth /usr/local/mysql/data
从上面命令可以看到，其实data目录是一个链接，指向了/opt/mysql_data。必须保证//opt/mysql_data的用户和权限（通常mysql数据库的权限为mysql:mysql）。

### 1.2 mysql体系结构

![img](https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fimg.136.la%2Fla15%2F2017051541336.png&refer=http%3A%2F%2Fimg.136.la&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1632192212&t=8ba0b6fd5031e14d2a4bf78f85d62797)

从图1-1可以发现，mysql由以下同部分组成：
连接池组件
管理服务和工具组件
Sql接口组件
查询分析器组件
优化器组件
缓冲（cache）组件
插件式存储引擎
物理文件

需要注意的是，存储引擎是基于表的，而不是数据库。要牢记图1-1的mysql体系结构，它对于以后深入理解mysql数据库会有极大的帮助。

### 1.3 mysql存储引擎

#### 1.31 innodb存储引擎

主要面向在线事务处理（OLTP）的应用。特点是行锁设计、支持外键，并支持类似于oracle的非锁定读，即默认读取操作不会产生锁。
Innodb存储引擎数据放在一个逻辑表空间中，可以将每一个表单独存放到一个独立的idb文件中，此外还支持用裸设备row disk来建立其表空间。
通过使用多版本并发控制（MVCC）来获得高并发性，并且实现了sql标准的4种隔离级别，默认为Repeatable级别。同时，使用一种被称为next-key locking 的策略来避免幻读（phantom）现象的产生。此外，还提供了插入缓冲(insert buffer)、二次写double write、自适应哈希索引adaptive hash index、预读read ahead等高性能和高可用的功能

采用了聚集clustered的方式，每张表的存储都是按主键的顺序进行存放。如果没有显式地在表定义时指定主键，innodb存储引擎会为每一行成一个6字节的rowid，并以此为主键。

#### 1.32 Myisam存储引擎

不支持事务、表锁设计，支持全文索引，主要面向一些OLAP数据库应用。

有些不需要事务的场景：在数据仓库中，如果没有ETL这些操作，只是简单的报表查询

另一个与众不同的是：他的缓冲池只缓存‘cache’索引文件，而不缓冲数据文件。

Myisam存储引擎表由MYD和MYI组成，MYD用来存放数据文件，MYI存放索引文件。

从5.0开始，MyISAM默认支持256TB的单表数据，更改空间参数：max_rows和avg_row_length

#### 1.3.3 NDB存储引擎

NDB的特点是数据全部放在内存中，从5.1开始可以将非索引数据放在磁盘上，因此主键查找速度极快，并且通过添加NDB数据存储节点Data Node可以线性地提高数据库性能，是高可用，高性能的集群系统

#### 1.3.4 Memory存储引擎

之前称为HEAP存储引擎，将表中的数据存放在内在中，如果数据库重启或发生崩溃，表中的数据都将消失。适合用于存储临时数据的临时表，以及数据仓库中的纬度表。默认使用哈希索引。
只支持表锁，并发性能较差，不支持TEXT和BLOB类型，最重要的是varchar是按照char的方式存储的，会浪费内存。

#### 1.3.5 Archive 存储引擎

只支持insert和select操作，从5.1开始支持索引。使用zlib算法将数据行row进行压缩后存储，比较1：10。非常适合存储归档数据，如日志信息。使用行锁实现高并发的插入操作，但本身不是事务安全存储引擎，目标主要是提供高速的插入和压缩功能。

#### 1.3.6 Federated存储引擎

不存放数据，只是指向一台远程mysql数据库服务器上的表。

#### 1.3.7 Maria 存储引擎

主要是用来取代Myisam，特点是：支持缓存数据和索引文件，应用了行锁设计，提供了mvcc功能，支持事务和非事务安全的选项，以及更好的BLOB字符类型的处理性能。

#### 1.38 其他存储引擎

Merge  CSV  Sphinx  Infobright 

### 1.4 各存储引擎之间的比较 略

查看存储引擎： show engines\G
支持MVCC的引擎：innodb  archive  NDB

### 1.5 连接mysql

连接mysql操作是一个连接进程和mysql数据库实例进行通信。本质上是进程通信。方式有管道、命名管道、命名字、TCP/IP套接字、UNIX域套接字。

#### 1.5.1 TCP/IP

Mysql -h192.168.0.1 -u david -p

#### 1.5.2 命名管道和共享内在

如果两个需要进程通信的进程在同一台服务器上，可以使用，在mysql数据库中必须在配置文件中启用--enable-named-pipe选项。4.1之后版本中，提供了共享内存的连接方式，在配置文件中添加--shard-memory实现，在连接时还必须使用--protoco=memory选项。

#### 1.5.3 UNIX域套接字

只能在客户端和数据库实例在一台服务吕上的情况下使用。在配置文件中指定路径，如--socket=/tmp/mysql.dock。
查找：show variables like ‘socket’;
连接方式：mysql -udavid -S /tmp/mysql.cock



## 第二章 innoDB 存储引擎

### 2.1  innodb 存储引擎概述

<img src="C:\Users\86132\AppData\Roaming\Typora\typora-user-images\image-20210822105425188.png" alt="image-20210822105425188" style="zoom:50%;" />





#### 2.3.1 后台线程

##### 1 master thread

是一个非常核心的后台线程，主要负责缓冲池中的数据异步刷新到磁盘，保证数据的一致性，包括脏页的刷新、合并插入缓冲（insert buffer）、UNDO页的回收等

##### 2 IO thread

在INNODB存储引擎中大量作用了AIO（Async IO）来处理写IO请求，这样可以极大提高数据库的性能。而IO Thread的工作主要是负责这些IO请求的回调（call back）处理。

从INNODB 1.0 开始，read thread 和 write thread 分别增大到了4个，分别使用innodb_read_io_threads 和 innodb_write_io_threads参数进行设置：

 show variables like 'innodb_version'\G

show variables like 'innodb_%io_threads'\G

show engine innodb status\G

可以看到io thread 0 为insert buffer thread    1 为log thread 。 之后就是根据innodb+read_io_threads及innodb_write_io_threads来设置的读写线程，并且读线程的ID总是小于写线程。

##### 3 Purge thread

事务被提交后，其所使用的undolog可能不再需要，因此需要purge thread 来回收已经使用并分配的undo页。

用户可以在配置文件中添加命令来启用独立的purgethread:  innodb_purge_threads=1

5.6版本开始支持多个purgethread, purgethread需要离散地读取undo页，这样也能更进一步利用磁盘的随机读取性能

##### 4 Page Cleaner Thread

作用是将之前版本中的脏页的刷新操作都放入到单独的线程中来完成。目的是为了减轻原Master Thread的工作及对于用户查询线程的阻塞，进一步提高InnoDB存储引擎的性能

### 2.3.2  内存

##### 1 缓冲池

InnoDB 存储引擎是基于磁盘存储的，并将其中的记录按照页的方式进行管理。因此可将其视为基于磁盘的数据库系统Disk-base Database 。由于CPU与磁盘的速度之间的鸿沟，基于磁盘的数据库系统通常使用缓冲池技术来提高数据库的整体性能。

缓冲池简单来说是一块内存区域，通过内存的速度来弥补磁盘速度较慢对数据库性能的影响。在数据库中进行读取页的操作，首先将从磁盘读到的**页**存放在缓冲池中，这个过程被称为将页“fix" 在缓冲池中。下一次读相同页时，首先判断该页是否在缓冲池中。若在缓冲池中，称为该页在缓冲池中被 命中，直接读取该面。否则，读取磁盘上的页。缓冲池中被修改的页被一种称为Checkpoint 的机制刷新回磁盘。

缓冲池的配置参数：innodb_buffer_pool_size

show variables like 'innodb_buffer_pool_size'\G

![image-20210822113541822](C:\Users\86132\AppData\Roaming\Typora\typora-user-images\image-20210822113541822.png)

缓冲池中的缓存数据页类型有：索引页、数据页、undo页、插入缓冲insert buffer、自适应哈希索引adaptive hash index、InnoDB 存储的锁信息lockinfo 、 数据字典信息data dictionary等。**不能简单认为缓冲池只是缓存 索引页和数据页，它们只是占缓冲池很大的一部分页已。**

允许有多个缓冲池实例。每个页根据哈希值平均分配到不同的缓冲池实例中。可以通过参数设置：innodb_buffer_pool_instances

show variables like 'innodb_buffer_pool_instances'\G    默认为1个

##### 2 LRU List 、 Free List 和 Flush List

数据库中的缓冲池是通过LRU（Lastest Recent Used，最近最少使用）算法来进行管理的。即最频繁使用的页在LRU列表的前端，而最少使用的页在LRU列表的尾端。当缓冲池不能存放新读取到的页时，将首先释放LRU列表中尾端的页。

在InnoDB 存储引擎中，缓冲池中的页默认为16KB，同样使用LRU算法对缓冲池进行管理。进行了优化，在LRU中加入了midpoint位置。新读取到的页不放到首部，而是放到midpoint位置。默认配置位置在LRU列表的5/8处。midpint位置由参数innodb_old_blocks_pct控制：

show variables like 'innodb_old_blocks_pct'\G      37  表示新读取的页插入到LRU**尾端的37%**处

midpoint之后的为old列表，之前的为new列表



**引入了另一个参数进一步管理LRU列表**，innodb_old_blocks_time 用于表示页读到到mid位置后需要等待多久才会加入到LRU列表的热端 

set global innodb_old_blocks_time=1000;



```sql
----------------------
BUFFER POOL AND MEMORY
----------------------
Total large memory allocated 137428992
Dictionary memory allocated 12093928
Buffer pool size   8191
Free buffers       1024
Database pages     6839
Old database pages 2504
Modified db pages  12
Pending reads      0
Pending writes: LRU 0, flush list 0, single page 0
Pages made young 60507338, not young 2328424533
0.00 youngs/s, 0.00 non-youngs/s
Pages read 50665349, created 4038350, written 44880368
0.00 reads/s, 0.18 creates/s, 1.41 writes/s
Buffer pool hit rate 1000 / 1000, young-making rate 0 / 1000 not 0 / 1000
Pages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/s
LRU len: 6839, unzip_LRU len: 0
I/O sum[575]:cur[1], unzip sum[0]:cur[0]
```



**FREE**

```sql
FREE页还不清楚，难道是数据库启动时，缓冲池中有数据，并且是存在Free页中？
```



LRU列表用来管理已经读取的页，但当数据库刚启动时，LRU列表是空的。这时页都存放在Free列表中。这时页都存放在Free列表中。当需要从缓冲池中分布时，首先从Free列表中查找是否有可用的空闲页，若有则将该页从free列表中删除，放入到LRU列表中。

当页从LRU列表的old部分加入到NEW部分时，称此时的操作为page made young,而没有移到NEW部分的操作称为page not made young 。可以通过命令show engine innodb status来观察LRU及FREE 列表的使用情况和运行状态。

可以看到当前buffer pool size 共有327679个页，即327679*16K ，总共5GB。free bufers 表示当前free列表中页的数量，databases pages表示 LRU列表中页的数量。free buffers 与databases pages 之和不等于buffer pool size。因为缓冲池中的页还可能分配给自适应哈希索引、lock信息、insert buffer 等页。这部分不需要LRU。

page made young 显示了LRU列表中页移动到前端的次数，youngs/s 每秒的值 

命中率：buffer pool hit rate  通常应该小于95% 。

<!--show engine innodb status 显示的不是当前的状态，而是过去某个时间范围内的innodb 存储引擎的状态。per second averages calculated from the last 24 seconds  24秒内的状态-->  



从5.6 版本开始可通过表来观察缓冲池状态：

select pool_id, hit_rate, pages_made_young, pages_not_made_young from information_schema.innodb_buffer_pool_stats;

观察每个LRU列表中每个页的具体信息：

select table_name,space,page_number,page_type from information_schema.innodb_buffer_page_lru where space=1;



支持压缩页的功能，即可原本16KB的页压缩为1、2、4、8KB。对于非16KB的页，是通过unzip_LRU列表进行管理的。**LRU中的页包含了unzip_LRU列表中的页**

通过表观察unzip_LRU列表中的页：

select table_name, space, page_number, compressed_size from information_schema.innodb_buffer_page_lru where compressed_size<>0



**FLUSH**

在LRU列表中的页被修改后，称该页为脏页（dirty page）, 即缓冲池中的页和磁盘上的页的数据产生了不一至。这时数据库会通过**CHECKPOINT**机制将脏页刷新回磁盘。 而FLUSH列表中的页即为脏页列表。需要注意的是**，脏页即存在于LRU列表中，也存在于FLUSH列表中**。LRU列表用来管理缓冲池中页的可用性，Flush列表用来管理将页刷新回磁盘，二者互不影响

Modified db pages 就显示了脏页的数量。

用表查看：

select table_name,space,page_number,page_type from information_schema.innodb_buffer_page_lru where oldest_modification>0;



##### 3 重做日志缓冲

**innodb 存储引擎的内存区**除了缓冲池外，还有重做日志缓冲（redo log buffer）。InnoDB存储引擎首先将重做日志信息先放入到这个缓冲区，然后按一定的频率将其刷新到重做日志文件。不需要很大，一般每秒钟一次。



show variables like 'innodb_log_buffer_size'\G

配置参数：innodb_log_buffer_size, 默认为8MB



以下三种情况会将重做日志缓中的内容刷新到外部磁盘的重做日志文件中（ib.logfile0,ib.logfile1）

-1Master thread 每一秒将重做日志缓冲刷到重做日志文件

-2 每个事务提交时会将重做日志缓冲刷到重做日志文件

-3 当重做日志缓冲剩余空间小于1/2时，重做日志缓冲刷新到重做日志文件。



##### 4 额外的内存池

在innodb 存储引擎中，对内存的管理是通过一种称为内存堆heap的方式进行的。在对本地数据结构本身的内存进行分配时，需要从额外的内存池中进行申请，当该区域的内存不够时，会从缓冲池中进行申请。

例如每个缓冲池中的帧缓冲还有对应的缓冲控制对象，这些对象记录了诸如LRU、锁、等待等信息，这些对象的内存要从额外内存池中申请。因此在申请了很大的innodb缓冲池时，也应考虑相应增加这个值 



### 2.4 Checkpoint 技术

当事务提交时先写重做日志，再修改页。当由于发生宕机而导致数据丢失时，通过重做日志来完成数据的恢复。这也是事务ACID中的D的要求。

思考下面的场景，如果重做日志可以无限地增大，同时缓冲池也足够大，能缓冲所有的数据库数据，那么是不是不需要将缓冲池中页的新版本刷新回磁盘。因为当发生宕机时，完全可以通过重做日志来恢复整个数据库系统中的数据到宕机发生的时刻，但是这需要两个前提条件：1 缓冲池可以缓存数据库中所有的数据 ； 2 重做日志可以无限增大。

即使满足上述两个条件，还有一个情况需要考虑：宕机后数据库的恢复时间。当数据库运行了几年时，重做日志恢复的代价会非常大。因此checkpoint检查点技术的目的是解决以下几个问题：

1缩短数据库的恢复时间； 2 缓冲池不够用时，刷新脏页； 3 重做日志不可用时，刷新脏页。

当数据库发生宕机时，数据库不需要重做所有的日志，因为checkpoint之前的页都已经刷新回磁盘。只需对checkpoint之后的重做日志进行恢复。大大缩短了恢复的时间。

?        当缓冲池不够用时，根据LRU算法会溢出最近最少使用的页，若此页为脏页，那么要强制执行checkpoint，将脏页也就是页的新版本刷回磁盘。

重做日志的设计都是循环使用，并不是让其无限增大。重做日志可以被重用的部分是指这些重做日志已经不再需要，即当数据库发生宕机时，数据库恢复操作不需要这部分的重做日志，因此可以被覆盖重用。若此时重做日志还需要使用，那么必须强制产生checkpoint。

对于innodb存储引擎而言其是通过LSN log sequence number 来标记版本的。LSN是8字节的数字，其单位是字节。每个页有LSN，重做日志中也有LSN，checkpoint也有LSN。

通过show engine innodb status 来观察：

```sql
---
LOG
---
Log sequence number 16469533
Log flushed up to   16469533
Pages flushed up to 16469533
Last checkpoint at  16469524
Max checkpoint age    80826164
Checkpoint age target 78300347
Modified age          0
Checkpoint age        9
0 pending log flushes, 0 pending chkp writes
552 log i/o's done, 0.00 log i/o's/second
```



在Innodb存储引擎内部，有两种Checkpoint，分别为：

?	**Sharp checkpoint**

?	**Fuzzy Checkpoint**

**Sharp checkpoint** 发生在数据库**关闭时**将**所有的脏页都刷新回磁盘**，这是默认的工作方式，即innodb_fast_shutdown=1. 但若数据库运行时也使用，那么可用性会受到很大的影响。故内部使用**Fuzzy Checkpoint** 进行页的刷新，即只刷新一部分脏页，而不是刷新所有的脏页回磁盘。

可能发生如下几种情况的Fuzzy Checkpoint:

**Master Thread Checkpoint**

?        差不多每秒或每十秒的速度刷新，这个过程是异步的，用户的查询线程不会阻塞。

**FLUSH_LRU_LIST Checkpoint**

?        因为INNODB存储引擎**需要保证LRU列表中需要有差不多100个空闲页可供使用**。从5。6版本开始，这个检查被放在一个单独的Page Cleaner 线程中进行，可通过参数innodb_lru_scan_depth控制LRU列表中可用页的数量 show variables like 'innodb_lru_scan_depth'

**Async/Sync Flush CHeckpoint**  (Async异步，sync同步)

?        指的是重做日志文件不可用的情况，这时需要强制将一些页刷新回磁盘，而此时脏页是从脏页从脏页列表中选取的。若将已经写入到重做日志的LSN记为redo_lsn，将已经刷新回磁盘最新页的LSN记为checkpoint_lsn，则-可定义：checkpoint_age = redo_lsn - checkpoint_lsn

?        再定义以下变量：

?        async_water_mark =  75% * total_redo_log_file_size

?        sync_water_mark =  90% * total_redo_log_file_size

当checkpoint_age<75% 不刷新

当90%<checkpoint_age<75%时，触发Async Flush，从flush列表中刷新，使满足<75%

当checkpoint_age>90% 这种情况一般很少发生，刷新使满足checkpoint_age<75%

从5.6版本开始，这部分的刷新操作放入到了单独的Page Cleaner Thread中，不会阻塞用户查询线程。



**Dirty Page too much Checkpoint**

?       即脏页的数量太多，导致innodb 存储引擎强制进行checkpoint, 为了保证缓冲池中有足够可用的页。可由参数控制：show variables like 'innodb_max_dirty_pages_pct'\G   75 表示当缓冲池中脏页的数量占据75%时，强制进行checkpoint 刷新一部分的脏页到磁盘。



### 2.5 Master Thread 工作方式

innodb 存储引擎的主要工作都是在一个单独的后台线程Masther Thread中完成的

#### 2.5.1 innodb 1.0.x 版本之前的Master Thread

Master thread 具有最高的线程优先级别，内部由多个循环loop组成：主循环loop 、后台循环backgroup loop、刷新循环flush loop、暂停循环suspend loop。Master Thread 会根据数据库运行的状态在loop、background loop 、 flush loop和suspend loop 中进行切换。

##### loop

loop被称为主循环，因为大多数的操作是在这个循环中，其中两大部分的操作：每秒和每10的操作。

##### **每秒一次的操作包括：**

1 日志缓冲刷新到磁盘，即使这个事务还没有提交（总是）；

**即使某个事务还没有提交，innodb存储引擎仍然每秒会将重做日志缓冲中的内容刷新到重做日志文件。这解释了为什么再大的事务提交的时间也是很短的**

2合并插入缓冲（可能）；

innodb 存储引擎会判断当前一秒内发生的IO次数是否小于5次，如果小于5次，innodb会认为当前的IO压力很小，可以执行合并插入缓冲的操作

3 至多刷新100个innodb 的缓冲池中的脏页到磁盘（可能）；

innodb 通过判断当前缓冲池中脏页的比例buf_get_modified_ratio_pct是否超过了配置文件中的innodb_max_dirty_pages_pct这个参数（默认为90，代表90%），如果超过了这个阈值，innodb存储引擎会将100个脏页写入磁盘中。

4如果当前没有用户活动，则切换到background loop（可能）。



##### 每十秒的操作

1 刷新100个脏页到磁盘可能 的情况下）：

2 合并至多5个插入缓冲（总是）：

3 将日志缓冲刷新到磁盘（总是）：

4 删除无用的Undo 页（总是）：

5 刷新100个或者10个脏页到磁盘（总是）。

在以上的过程中，判断过去10少之内磁盘的IO操作是否小于200次，如果是，则将100个脏页刷新到磁盘。接着会合并插入缓冲。不同于每秒的是，这次的合并插入缓冲操作总会在这个阶段进行。之后，会再进行一次将日志缓冲刷新到磁盘的操作。这和每秒一次时发生的操作是一样的。接着会进一步执行full purge 操作，即删除无用的undo页，每次最多尝试回收20个undo页。

然后，判断缓冲池中脏页的比例（buf_get_modified_ratio_pct)，如果有超过70%的脏页，则刷新100个脏页到磁盘，如果脏页的比例小于70%，则刷新10%的脏页到磁盘。

##### background loop

接着看background loop，若当前没有用户活动（数据库空闲时）或者数据库关闭（shutdown)，就会切换到这个循环。background loop 会执行以下操作：

1 删除无用的Undo页（总是）：

2 合并20个插入缓冲（总是）：

3 跳回到主循环（总是）：

4 不断刷新100个页直到符合条件（可能，跳转到flush loop中完成）。

若flush loop中也没有什么事情可以做了，innodb 存储引擎会切换到suspend_loop，将master thread挂起，等待事件的发生。若用户启用（enable)  了innodb 存储引擎，却没有使用任何innodb存储引擎的表，那么master thread总是处于挂起的状态。



#### 2.5.2 innodb 1.2.x 版本之前的Master Thread

从前面的伪代码来看，无论何时，innodb存储引擎最大只会刷新100个脏页到磁盘，合并20个插入缓冲。当大于这个值时，会导致恢复的时间更久，尤其是对于insert buffer。

提供了参数innodb_io_capacity，用来表示磁盘IO的吞吐量，默认为200。对于刷新到磁盘页的数量，会按照innodb_io_capacity 的百分比来进行控制。规则如下：

1 在合并插入缓冲时，合并插入缓冲的数量 为innodb_io_capacity值的5%；

2 在从缓冲区刷脏页时，刷新脏页的数量为innodb_io_capacity。

另一个问题是参数innodb_max_dirty_pages_pct默认值的问题，默认值为90，意味着脏页占缓冲池的90%，但每秒刷新缓冲池和flush loop时会判断这个值，如果大于该值才刷新100个脏页，经测试最终默认值设置为75。

另一个参数innodb_adaptive_flushing(自适应地刷新)，该值影响每秒刷新脏页的数量。通过判断产生重做日志（redo log) 的速度来决定最合适的刷新脏页数量。因此，当脏页的比例小于innodb_max_dirty_page_pct时，也会刷新一定量的脏页。



还有一个改变是：之前每次进行full purge 操作时最多回收20个undo页，现在可动态修改innodb_purge_batch_size 

#### 2.5.3 innodb 1.2.x版本的Master Thread

其中srv_master_do_idle_tasks()就是之前版本中每10秒的操作，srv_master_do_active_tasks()处理的就是之前每秒中的操作。同时对于刷新脏页的操作，从Master thread线程中分离到一个单独的Page Cleaner Thread中。

主线程的作用：1 将日志缓冲刷新到磁盘。 2 合并插入缓冲。



### 2.6 innodb 关键特性

1 插入缓冲 Insert Buffer

2 两次写 Double Write

3 自适应哈希索引 Adaptive Hash Index

4 异步IO Async IO

5 刷新邻接页 Flush Neighbor Page

#### 2.6.1 插入缓冲

##### 1 insert buffer

insert bufer 和数据页一样，也是物理页的一个组成部分。除uuid之外的插入聚集索引primary key 一般是顺序插入的，不需要磁盘的随机读取。但是对于非聚集索引叶子节点的插入不再是顺序的了，这时就需要离散地访问非聚集索引页。

对于非聚集索引的插入或更新操作，不是每一次直接插入到索引页中，而是先判断插入的索引页是否在缓冲池中，若在，则直接插入；若不在，则先放入到一个insert buffer对象中，好似欺骗数据库这个非聚集的索引已经插入到叶子节点，而实际并没有，只是存放在一个位置。然后再以一定的频率和情况进行insert buffer和辅助索引页子节点的merge合并操作，这时通常能将多个插入合并到一个操作中（因为在一个索引页中），这就大大提高了对非聚集索引插入的性能。insert buffer的使用需要同时满足以下两个条件：1 索引是辅助索引(secondary index)；2 索引不是唯一(unique)的

可通过命令show engine innodb status 来看插入缓冲的信息

##### 2 change Buffer

可视为insert buffer 的升级。

控制开启各种buffer的选项：show variables like '%innodb_change_buffering%'

用来控制chage buffer 最大使用内存量show variables like '%innodb_change_buffer_max_size%'，默认值为25，表示最多使用1/4的缓冲池空间。最大有效值为50。

```sql
-------------------------------------
INSERT BUFFER AND ADAPTIVE HASH INDEX
-------------------------------------
Ibuf: size 1, free list len 3092, seg size 3094, 160063 merges
merged operations:
 insert 501019, delete mark 7003892, delete 113240
discarded operations:
 insert 0, delete mark 0, delete 0
 
 seg size 显示了当前insert buffer 的大小为3094*16K，
 size 代表已经合并记录页的数量；free list len 代表了空闲列表的长度；
 
 insert 表示insert buffer； delete mark 表示delete buffer； delete 表示purge buffer ; discarded operations 表示 change buffer 发生merge时，表已经被删除，此时就无需再将记录合并(merge)到辅助索引中了。
```

##### 3 insert buffer 的内部实现

**insert buffer 的数据结构是一颗B+树。**全局只有一棵insert buffer B+树，负责对所有的表的辅助索引进行insert buffer。**存放在共享表空间中，默认就是ibdata1中**。试图通过独立表空间ibd 文件恢复表中数据时，往往会导致checkt able失败，因为辅助索引中的数据可能还在insert buffer中，也就是共享表空间中，所以通过ibd文件进行恢复后，还需要进行repair table 操作来重建表上所有的辅助索引。

##### 4 merge insert buffer

insert buffer 中的记录何时合并（merge）到真正的辅助索引中：

1 辅助索引页被读取到缓冲池

2 insert buffer bitmap页追踪到该辅助索引页已无可用空间；

 insert buffer bitmap页用来追踪每个辅助索引页的可用空间，并至少有1/32页的空间。若检测到插入记录后可用空间会小于1/32页，则会强制进行一个合并操作，即强制读取辅助索引页，将insert buffer B+树中该页的记录及待插入的记录插入到辅助索引页中。

3 master thread

**master thread每秒或每10秒会进行一次Merge insert buffer 的操作**

#### 2.6.2 两次写



当数据库宕机时，如果发生写失效，可以通过**重做日志**（redo log）进行恢复。但必须清楚地认识到，重做日志中记录的是对页的物理操作，如偏移量800，写'aaaa'记录。如果这个页本身已经发生了损坏，再对其进行重做是没有意义的。

-

这就是说，在应用重做日志前，用户需要一个页的副本，当写入失效发生时，先通过页的副本来还原该页，再进行重做，这就是double write.

double write 由两部分组成，一部分是内存中的doublewrite buffer，大小为2MB，另一部分是物理磁盘上共享表空间中的连接128个页，即2个区（extent），大小同样为2MB。在对缓冲池的脏页进行刷新时，并不直接写磁盘，而是会通过memcpy 函数将脏页先复制到内存中的doublewrite buffer，之后通过doublewrite buffer 再分两次，每次1MB顺序地写入共享表空间的物理磁盘上，然后马上调用fsync 函数，同步磁盘，避免缓冲写带来的问题。在这个过程中，因为double write页是连续的，因此这个过程是顺序写的，开销并不大。在完成doublewrite页的写入后，再将doublewrite buffer中的页写入各个表空间文件中，此时的写入则是离散的。可以通过以下命令观察到double write 的运行情况：

```sql
show global status like 'innodb_dblwr%'

Variable_name	Value
Innodb_dblwr_pages_written	40048882  一共写了多少页
Innodb_dblwr_writes	1744654  实际写入次数
两者相比小于64：1  ，说明系统写入压力并不是很高
```

缓冲池 --> double write buffer  --> 共享表空间ibdata1  -->  同步给各自的单独表空间.ibd

如果操作系统在将页写入磁盘的过程中发生了崩溃，在恢复过程中，innodb存储引擎可以从共享表空间中的doublewrite中找到该页的一个副本，将其复制到表空间文件，再应用**重做日志**。

<!--innodb是按页写入的吗？否则怎么会从doublewrite 中找到该页的一个副本？-->

在默认的情况下所有的页的刷新首先都需要放入到doublewrite中，因此该变量（show global status 中innodb_buffer_pool_pages_flushed）应该和innodb_dblwr_pages_written 一致(若不一致，要以此为准)。

参数skip_innodb_doublewrite 可以禁止使用doublewrite功能，在从机器上可以，但对于需要提供数据高可靠性的主服务器上，任何时间都应确保开启。

注意：有些文件系统本身就提供了部分写失效的防范机制，如ZFS文件系统。

#### 2.6.3 自适应哈希索引

时间复杂度为O(1), 即一般仅需要一次查找就能定位数据。而B+树的查找次数，取决于B+ 树的高度，在生产环境中，B+树的高度一般为3~4层，故需要3~4次的查询。

innodb 存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引可以带来速度提升，则建立哈希索引，称之为自适应哈希索引(Adaptive Hash Index, AHI). AHI是通过缓冲池的B+树页构造而来，因此建立的速度很快，不需要对整张表构建哈希索引。会自动根据访问的频率和模式来自动地为某些热点页建立哈希索引。

AHI有一个要求，即对这个页的连续访问模式必须是一样的。访问模式一样指的是查询的条件一样，只能用来搜索等值的查询

where a=XXX    

where  a=XXX and b=XXX

此外还有如下要求：

1 以该模式访问了100次

2 页通过该模式访问了N次，其中N=页中记录*1/16

根据官方文档显示，启用AHI后，读取和写入速度可以提高2倍，辅助索引的连接操作性能可以提高5倍。

```sql
show engine innodb status

-------------------------------------
INSERT BUFFER AND ADAPTIVE HASH INDEX
-------------------------------------
Ibuf: size 1, free list len 3092, seg size 3094, 160063 merges
merged operations:
 insert 501019, delete mark 7003892, delete 113240
discarded operations:
 insert 0, delete mark 0, delete 0
Hash table size 34673, node heap has 0 buffer(s)
Hash table size 34673, node heap has 1 buffer(s)
Hash table size 34673, node heap has 7 buffer(s)
Hash table size 34673, node heap has 70 buffer(s)
Hash table size 34673, node heap has 2 buffer(s)
Hash table size 34673, node heap has 236 buffer(s)
Hash table size 34673, node heap has 5 buffer(s)
Hash table size 34673, node heap has 7 buffer(s)
6819.60 hash searches/s, 557.50 non-hash searches/s --哈希使用信息
```

show variables like 'innodb_adaptive_hash_index'

可以禁用或启用，默认为开启状态



#### 2.6.4 异步IO

为了提高磁盘操作性能，当前的数据库系统都采用异步IO（Asynchronous IO）的方式来处理磁盘操作。

SYNC IO即每进行一次IO操作，需要等待此次操作结束 才能继续接下来的操作。没有必要。

用户可以在发出一个IO请求后立即再发出另一个IO请求，当全部IO请求发送完毕后，等待所有IO操作的完成，这就是AIO。AIO的另一个优势是可以进行IO Merge 操作，也就是将多个IO合并为1 个IO，这样可以提高IOPS的性能。

#### 2.6.5 刷新临近页

工作原理：当刷新一个脏页时，innodb存储引擎会检测该页所在的区(extent)的所有页，如果是脏页，那么一起进行刷新。好处是可以将多个IO写入操作合并为一个IO操作，

有两个问题：1 是不是将可能不怎么脏的页进行了写入，而该页之后又很快变成脏页？2 固态硬盘有着较高的IOPS是否需要此特性？

为此提供了参数show variables like 'innodb_flush_neighbors'

### 2.7 启动、关闭与恢复 

在关闭时innodb_fast_shutdown 影响着表的存储引擎为innodb的行为。可取值为0 1 2
0 表示数据库关闭时，innodb需要完成所有的full purge 和 merge insert buffer，并且 将所有的脏页刷新回磁盘。有时甚至需要几个小时来完成。如果在innodb升级时，必须将这个参数调为0，然后关闭数据库。

1 是参数innodb_fast_shutdown的默认值，表示不需要完成上述的full purge 和 merge insert buffer操作，但是在缓冲池中的一些数据脏页还是会刷新回磁盘。

2 表示不完成full purge 和 merge insert buffer操作，也不将缓冲池中的数据脏页写回磁盘，而是将日志都写入日志文件。这样不会有任何事务的丢失，但是下次mysql数据库启动时，会进行恢复操作(recovery)

如果用kill命令关闭数据库，在mysql数据库运行中重启了服务器，或者在关闭数据库时，将参数innodb_fast_shutdown设为了2时，在下次数据库启动时都会对innodb存储引擎的表进行恢复操作。


参数innodb_force_recovery影响了整个innodb存储引擎恢复的状况。默认为0，代表当发生需要恢复时，进行所有的恢复操作，当不能进行恢复时，如数据页发生了corruption，mysql数据库可能发生宕机，并把错误写入错误日志中去。

某些情况 不需要进行完整恢复，如alter table发生了意外，对于大表来说，数据库重启时回滚需要很长时间，可以删除表，从备份中重新导入表，可能要远远快于回滚操作。


参数innodb_force_recovery还可以设置为6个非零值：1～6：大的数字表示包含了前面所有小数字表示的影响
1 SRV_FORCE_IGNORE_CORRUPT:忽略检查到的corrupt页。
2 SRV_FORCE_NO_BACKGROUND:阻止Master Thread线程的运行，如Master Thread线程需要进行full purge 操作，而这会导致crash.
3 SRV_FORCE_NO_TRX_UNDO: 不进行事务的回滚操作。
4 SRV_FORCE_NO_IBUF_MERGE: 不进行插入缓冲的合并操作。
5 SRV_FORCE_NO_UNDO_LOG_SCAN: 不查看撤销日志（Undo Log），Innodb存储引擎会将未提交的事务视为已提交。
6 SRV_FORCE_NO_LOG_REDO: 不进行前滚的操作
需要注意的是在设置大于0后，用户可以对表进行select create drop操作，但insert update delete这类DML操作是不允许的。



## 第三章 文件 
参数文件:实例启动时在哪里可以找到数据库文件，并且指定某些初始化参数，这些参数定义了某种内存结构的大小等设置，还会介绍各种参数的类型。
日志文件：用来记录mysql实例对某种条件做出响应时写入的文件，如错误日志，二进制日志，慢查询日志，查询日志文件等
socket文件：当用UNIX域套接字方式进行连接时需要的文件。
pid文件：Mysql实例的进程ID文件。
Mysql表结构文件：用来存放Mysql表结构定义文件。
存储引擎文件：因为Mysql表存储引擎的关系，每个存储引擎都会有自己的文件来保存各种数据。这些存储引擎真正存储了记录和索引等数据。本章主要介绍与InnoDB有关的存储引擎文件。

### 3.1 参数文件
上面已经介绍过，当Mysql实例启动时，数据库会先去读一个配置参数文件，用来寻找数据库的各种文件所在位置以及指定某些初始化的参数，这些参数通常定义了某种内在结构有多大等。顺序见：mysql --help | grep my.cnf 如果没有配置文件，会采用安装时的默认值。MySQL的参数文件是以文本方式进行存储的。
#### 3.1.1 什么是参数
可以把数据库参数看成一个键/值（key/value)对。可以通过命令**show variables **查看数据库中的所有参数。

#### 3.1.2 参数类型
可以分为两类：**动态（dynamic)参数  静态（static）参数**
动态参数意味着可以在mysql实例运行中进行更改，静态参数说明在整个实例生命周期内都不得进行更改，就像只读的。可以通过set命令对动态参数进行修改：
set
| [global | session ] system_var_name = expr
| [@@global. | @@session. | @@ ] system_var_name = expr

### 3.2 日志文件
MySQL数据库中常见的日志文件有：
错误日志 Error Log、 二进制日志 Bin Log 、慢查询日志 Slow Query Log 、 查询日志 Log
#### 3.2.1 错误日志
错误日志对Mysql的启动、运行、关闭过程进行了记录。DBA从该文件定位问题。该文件记录了所有的错误信息、也记录了一些警告信息或正确的信息。位置： show variables like 'log_error'

#### 3.2.2 慢查询日志
可以帮助DBA定位可能存在的问题的sql语句，从而进行sql语句层面的优化。默认情况下，mysql数据库并不启动慢查询日志，查看设定的慢查询时间，默认10（秒）：show variables like 'long_query_time'  -- 等于的时间也会被记下
是否开启：show variables like 'slow_query_log'\G
另一参数：log_queries_not_using_indexes,会记下没有使用索引的语句

将MySQL慢查询日志写入表或文件的设置为。set global log_output='table | file';

mysql5.6 新增log_throttle_queries_not_using_indexes,表示每分钟允许记录到slow log且未使用索引的语句次数。默认为0.表示没有限制。会导致slow log文件的大小增加，应当对此参数进行配置。

分析日志命令：mysqldumpslow， 如希望得到执行时间最长的10条语句：mysqldumpslow -s al -n 10 david.log


慢查询日志放在一张表中mysql.slow_log

参数log_output指定了慢查询日志的输出格式，默认为file,如果设为table就可以在mysql.slow_log表中查了。此参数是动态，全局的。

理性表定义，先关闭慢查询，再打开：set global slow_query_log=off;     alter table mysql.slow_log engine=MyISAM;

因数据在缓冲池中，运行时间非常短，增加了逻辑读取logical reads和物理读取physical reads的统计：这里的物理读取指从磁盘进行IO读取的次数，逻辑读取包含所有的读取，不管是磁盘还是缓冲池。
逻辑读取配置参数：long_query_io 默认为100，即表示对于逻辑读取次数大于100次的sql语句，记录到slow log中，还增加了启用slow log的方式：slow_query_type,可选值：0：不记录；1 根据运行时间记录；2 根据逻辑IO次数记录；3 根据运行时间和逻辑IO次数进行记录。


#### 3.2.3 查询日志
记录了mysql数据库所有的请求信息，默认文件名为：主机名.log  对未正确执行的sql也会记录，同样在表中：mysql.general_log

#### 3.2.4 二进制日志
记录了对数据库执行更改的所有操作，不包括select show 这类操作。如果操作本身没有导致数据库变化，可能也会写入二进制文件。
查看文件：show binlogevents in 'mysqld.0000008'\G

**开启binlog 在配置文件中要加上：server id=1**

**生成新日志文件：flush logs**

*# 不让 db3 db4 记录binlog* [mysqld] binlog_ignore_db = db3



二进制日志主要有以下几种作用：

1 恢复：如全备文件恢复，可用point-in-time的恢复。 2 复制：如主从复制。 3 审计：可判断是否有注入的攻击

启动参数配置：log-bin[=name]. 查看：show variables like 'datadir'; system ls -lh /usr/local/mysql/data/;
bin_log.index为二进制的索引文件，用来存储过往产生的二进制日志序号，不建议手工修改。

以下配置文件的参数影响着二进制日志记录的信息和行为：
**max_binlog_size:** 默认最大值为1G，超过会生产新文件。
**binlog_cache_size:** 默认为32K，事务表未提交时，二进制会被记录到此缓存中去，等提交时直接将缓冲中的二进制日志写入二进制日志文件；此值是基于会话的，会为每个事务分配，所以不能设置过大。当事务记录大于32K时，会把缓冲中的日志写入一个临时文件，因此又不能设置的太小。通过show global status查看binlog_cache_use（使用缓存次数）\binlog_cache_disk_use（使用临时文件次数）的状态，可以判断此值是否合适。
**sync_binlog**:因为二进制缓冲的存在，如果宕机，可能会有一部分数据写入了缓冲，而没有写入二进制文件。此参数代表每写多少次缓冲，就同步到磁盘。如果设计为1，即sys_binlog=1，表示同步写磁盘。这时写操作不使用操作系统的缓冲写二进制日志，默认为0。
如果设为1，也有一种情况，当未提交时将记录写入二进制日志，但突然宕机，下次启动数据库时会回滚，但二进制日志已经记录了该事务信息不能被回滚。这个问题可通过innodb_support_xa设为1来解决，虽然与XA事务有关，但确保了二进制日志和innodb存储引擎数据文件的同步。
**binlog-do-db:**
**binlog-ignore-db:**表示写入或忽略哪些库的日志，默认为空。
**log-slave-update:**如果当前数据库是复制中的slave角色，他不会将从主库取得并执行的日志写入自己的二进制日志文件中去，如果要写入，就要设置此值。**框架:master=>slave=>slave必须设置此值**.
**binlog_format:**十分重要。是动态函数，可以全局和当前会话修改：set @@global.binlog_format='row';
二进制日志的记录格式：
**statement :**记录逻辑sql语句
**row ：**记录表行物理的情况。 类似于oracle的物理Standby(还是有些区别)
**mixed ：** 默认采用statement记录逻辑语句，但在有些情况下会使用row格式，可能的情况有：1存储引擎为NDB；2 使用了UUID()、USER()、CURRENT_USER()、FOUND_ROWS()、ROW_COUNT()等不确定函数。3 使用了insert delay语句；4使用了用户定义函数(UDF)；5 使用了临时表

binlog_format默认为row,但文件会增大很多，对磁盘空间有要求，而由于复制是采用传输二进制文件方式实现的，因此网络开销也有所增加。
要查看二进制日志文件必须要用mysqlbinlog. 对于statement格式的二进制文件使用看到的就是执行的逻辑语句：
mysqlbinlog -- start-position=2093 test.00004。
但如果是row格式的记录方式，就会变得不可读。要加上-vv或-v 就能清楚看到执行的具体信息了：
mysqlbinlog -vv --start-position=2093 test.00004。


### 3.3 套接字文件
 本地连接的方式，一般在/tmp目录下：show variables like 'socket'\G

### 3.4 PID文件
mysql 实例启动时，会将自己的进程ID写入此文件：show variables like 'pid_file'\G

### 3.5 表结构定义文件 
无论什么存储引擎，mysql都有一个以frm为后缀名的文件，这个文件记录了该表的表结构定义。frm还用来存放视图的定义v_a.frm。可用cat查看，此文本文件。

### 3.6 innodb 存储引擎文件
#### 3.6.1 表空间文件
默认表空间文件：默认配置下会有个初始大小10M，名为ibdata1的文件。
参数:[mysqld] 
innodb_data_file_path=/db/ibdata1:200M;/dr2/db/ibdata2:200M:autoextend
这里将/db/ibdata1和/dr2/db/ibdata2两个文件组成表空间。若这两个文件在不同的磁盘上，磁盘的负载可能被平均，提高数据库的性能。该文件可以自动增长。设置参数后，所有基于innodb存储引擎的表的数据都会记录到该共享表空间中。
独立表空间innodb_file_per_table:此参数可以让每个表产生一个独立表空间，命名规则：表名.ibd。
需要注意的是，这些单独的表空间文件仅存储该表的**数据、索引和插入缓冲BITMAP**信息，其余信息（）还是在默认的表空间中。

#### 3.6.2 重做日志文件
默认两个：ib_logfile0和ib_logfle1 官方手册称为innodb存储引擎的日志文件，更准确的定义一样是重做日志文件（redo log file)。他们记录了innodb存储引擎的事务日志。当发生宕机等情况时，innodb会使用重做日志恢复到掉电前的时刻，以保证数据的完整性。
至少有一个重做日志文件组，每个文件组下至少有2个重做日志文件。在日志组中每个重做日志文件的大小一致，并以循环写入的方式运行。
下列参数影响着重做日志文件的属性：
innodb_log_file_size  5.6后大小不超过512GB。
innodb_log_files_in_group  指定了日志文件数量，默认为2
innodb_mirrored_log_groups 指定了日志镜像文件组的数量，默认为1
innodb_log_group_home_dir 指定了路径，默认为mysql数据库的数据目录下

重做日志不能设置得太大，因为在恢复时可能需要很长时间；又不能太小，否则会导致一个事务的日志多次切换重做日志文件，会频繁地发生async checkpoint 导致性能的抖动。因为重做日志有一个capacity变量，该值代表了最后的检查点不能超过这个阈值，如果超过则必须将缓冲池中脏页列表中的部分脏数据页写回磁盘，这时会导致用户线程的阻塞。

重做日志和二进制日志的区别：
1 二进制日志会记录mysql数据库有关引擎的所有日志，重做日志只记录innodb本身的事务日志。
2 二进制日志不管是statement row mixed都是关于一个事务的具体操作内容，是逻辑日志。而innodb记录的是关于每个页page的更改的物理情况。
3 写入时间不同。二进制日志文件公在事务提交前进行提交，即只写磁盘一次。而在事务进行的过程中，不断有重做日志条目被写入重做日志文件。

重做日志条目结构：
redo_log_type 占用1字节，表示重做日志的类型
space 表示表空间的ID，但压缩至可能小于4字节
page_no 表示页的偏移量，同样压缩
redo_log_body 重做日志的数据部分，恢复时需要调用相应的函数进行解析

写入方式：先写入一个重做日志缓冲（redo log buffer），然后按照一定的条件顺序地写入日志文件。往磁盘写入时，按512个字节，也就是一个扇区的大小进行写入。因为扇区是写入的最小单位，因此可以保证写入必定是成功的。因此重做日志的写入过程中不需要doublewrite.

写入条件：主线程每秒会将重做日志缓冲写入磁盘的重做日志文件中，不论事务是否提交；另一个触发过程是由参数innodb_flush_log_at_trx_commit控制，表示在提交时，写入重做日志。

参数：innodb_flush_log_at_trx_commit
0 事务提交时不写入磁盘，而是等待由主线程每秒的刷新
1 和0不同的是在提交时将重做日志同步写到磁盘。
2 表示异步写入磁盘，即写到文件系统的缓存中。

因此为保证ACID的持久性，此参数必须设为1，也就是每当事务提交时，就必须确保事务都已经写入重做日志文件。

## 第4章 表
表就是关于特定实体的数据集合，这也是关系型数据库模型的核心

### 4.1 索引组织表
在innodb存储引擎中，表都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表（index organized table）.每张表都有一个主键，如果在创建表时没有显式地定义主键，则会按如下方式选择或创建主键：
1 首先判断表中是否有非空的唯一索引，如果有，则该列即为主键。如果有多个，则选择第一个创建的
2 如果不符合上述条件，则自动创建一个6字节大小的指针。

### 4.2 innodb 逻辑存储结构
所有数据都被逻辑地存放在一个空间中，称之为表空间。表空间又由段segment、区extent、页page 组成。页在一些文档中有时也称为块

#### 4.2.1 表空间
表空间可以看做是innodb存储引擎逻辑结构的最高层，所有的数据都存放在表空间中。
需要注意的是，这些单独的表空间文件仅存储该表的数据、索引和插入缓冲BITMAP信息，**其余信息还是在默认的表空间中，如回滚undo信息，插入缓冲索引页、系统事务信息，二次写缓冲double write buffer等**。
所以共享表空间还是会不断增大，如果事务回滚，则共享表空间也不会缩小，但此部分数据会标记为可用空间，供下次undo使用。

#### 4.2.2 段
表空间是由各个段组成，觉见的段有数据段、索引段、回滚段等。索引组织表：数据即索引，索引即数据。那么数据段即为B+树的叶子节点，索引段即为B+树的索引节点或非叶子节点。回滚段较为特殊，将在后面单独介绍。
对段的管理都是由引擎自身所完成，不能也不必要对其进行控制。

#### 4.2.3 区
区是由连续页组成的空间，任何情况下每个区的大小都为1MB。为了保证区中页的连续性，innodb存储引擎一次从磁盘申请4～5个区。默认情况下，页的大小为16KB，即一个区中一共有64个连续的页。

压缩页参数：innodb_page_size可将默认页的大小设置为4k、8k，但是页中的数据不压缩，这时区中页的数量为256、128.不论页怎么变，区的大小总是1M。
创建表的默认大小是96KB（8.0默认是112K），而不是1MB。这是因为在每个段开始时，先用32个页大小的碎片页来存放数据。在使用完这些页之后才是64个连续页的申请。对于一些小表来说，可以节省磁盘容量。

#### 4.2.4 页
页是innodb 磁盘管理的最小单位。默认为16KB。若设置innodb_page_size后，则不可以对其再进行修改。

在innodb存储引擎中，觉的页类型有8种：
数据页（B-tree Node）
undo页（undo Log Page）
系统页（System Page）
事务数据页（Transaction system Page）
插入缓冲位图页（Insert Buffer Bitmap）
插入缓冲空闲列表页（Insert Buffer Free List）
未压缩的二进制大对象页（Uncompressed BLOB Page）
压缩的二进制大对象页（compressed BLOB Page）

#### 4.2.5 行
Innodb 存储引擎是面向列的（row-oriented），也就是说数据是按行进行存放的。每个页存放的行记录也是有硬性定义的，最多允许存放16KB/2-200行的记录，即7992行记录。

存在有column-oriented的数据库，Mysql infobright存储引擎就是按列存放数据。这对于数据仓库下的分析类sql语执行及数据压缩非常有帮助。类似的数据库还有Sybase IQ \  Google Big Table. 面向列的数据库是当前数据库发展的一个方向。


### 4.3 INNODB 行记录格式
InnoDB存储引擎提供了Compact和Redundant两种格式，默认为Compact，Redundant是为了兼容之前的版本
show tables status like 'table_name'

#### 4.3.1-4 compact 行记录格式 （略） 最新为Dynamic
4.3.5 Char行行结构存储：对于多字节的字符编码，Char类型不再代表固定长度的字符串了，如UTF-8下的Char（10）可以存储10-30字节的字符，Innodb存储引擎内部视为变长字符类型。
多字节字符：多个字节表示一个字符的字符集。 此情况下，CHAR和VARCHAR没有实际存储没有区别。

### 4.4 INNODB页结构
页是InnoDB存储引擎管理数据库的最小磁盘单位。页类型为B-tree Node的页存放的即是表中行的实际数据。具体（略P120）
需要牢记的是，B+树索引本身并不能找到具体的一条记录，能找到只是该记录所在的页。**数据库把页载入到内存**，然后通过 Page Directory再进行二叉查找。只不过二叉查找的时间复杂度很低，同时在内存中的查找很快，因此通常忽略这部分查找所用的时间。

### 4.5 Named File Formats机制
新版本提供了新的页数据结构支持表压缩功能，完全的溢出大变长字符类型字段的存储。通过此机制来解决不同版本下页结构的兼容性问题。


### 4.6 约束
#### 4.6.1 数据完整性
约束机制，提供了一条强大而简单的途径来保证数据库中数据的完整性。一般有三种形式：
1 实体完整性保证表中有一个主键。
2 域完整性保证数据每列的值满足特定的条件：2.1 选择合适的数据类型。2.2外键约束。2.3编写触发器。2.4考虑用DEFAULT。
3 参照完整性保证两张表之间的关系：外键，触发器。
几种约束：Primary Key, Unique_key, Foreign_key, Default, Not null

#### 4.6.2 约束的创建和查找
1 表建立时就进行约束定义
2 利用 alter table 命令来进行创建约束

#### 4.6.3 约束和索引的区别
约束更是一个逻辑的概念，用来保证数据的完整性，而索引是一个数据结构，即有逻辑上的概念，在数据库中还代表着物理存储的方式。

#### 4.6.4对错误数据的约束
如向NOT　NULL的字段中插入一个NULL，会将其更改为0再进行插入。插入非法日期也不会报错。ENUM值也是一样情况不报错。
即MySQL数据库提示报错而不是警告，必须设置参数sql_mode,用来严格审核输入的参数: set sql_mode = 'strict_trans_tables'。可设置的值很多，可参考官方手册。

触发器与外键不常用--略

### 4.8 分区表
#### 4.8.1分区概述
分区功能并不是在存储引擎层完成。mysql数据库支持的分区为水平分区，并不支持垂直分区。Mysql数据库的分区是局部分区索引，一个分区中即存放了数据又存放了索引。不支持的全局分区是指，数据存放在各个分区中，但是所有数据的索引放在一个对象中。
查看启用状态：show variables like '%partition%'\G  or   show plugins\G
在OLTP应用中，对于分区的使用应该非常小心。
支持的分区类型：
1 RANGE分区：行数据基于属于一个给定连续区间的列值被放入分区。
2 LIST分区：面向的是离散的值。
3 HASH分区：根据用户自定义的表达式的返回值来进行分区，返回值不能是负数
4 KEY分区：根据数据库提供的哈希函数来进行分区。
不论哪种分区，如果表中存在主键或唯一索引时，**分区列必须是唯一索引的一个组成部分**，唯一索引是可以允许null值(不允许多个NULL值！).

#### 4.8.2 分区类型
1 RANGE分区 --明确指定值
表不再是一个ibd文件组成了，而是由建立分区时的各个分区的ibd文件组成。　定义 less than maxvalue：无限大。
按年份分区，如果要删除2008年的数据，只需要删除2008年数据所在的分区即可
对于日期，优化器只能对year(),to_days(),to_second(),unix_timestamps()这类函数进行优化选择，要注意分区函数parition by range(to_days(date))

2 LIST 分区 --明确指定值
LIST分区和RANGE分区非常相似，只是分区列的值是离散的，而非连续的。
若遇到未定义的值时，MyISAM引擎会将之前的行数据都插入，但之后的不会插入。InnoDB存储引擎将其视为一个事务，因此没有任何插入。

3 HASH分区
HASH分区的目的是将数据均匀地分布到预先定义的各个分区中，保证各分区的数据量大致是一样的。
要在create table 语句上添加一个"partition by hash(expr)"子句，expr是一个返回一个整数的表达式。
mod(year('2020-04-01'),4)=MOD(2010,4)=2

4 KEY 分区
和HASH相似，不同之处在于HASH分区使用用户定义的函数进行分区，KEY分区使用MySQL数据库提供的函数进行分区。
关键字LINEAR：分区编号是通过2的幂（powers-of-two）算法得到的，而不是通过模数算法。

5 columns分区
前面四种分区的条件是：数据必须是整形interger，如果不是整形，那应该需要通过函数将其转化为整形，如year()等
而columns可以视为range and list分区的一种进化，可以直接使用非整形的数据进行分区，分区根据类型直接比较而得，不需要转化为整形。此外还可以对多个列的值进行分区。
支持以下类型：所有的整型类型，如int smallint,tinyint,bigint。不支持float and decimal
日期类型，如：data and datetime 不支持其余的日期类型。
字符串类型，如：char varchar binary and varbinary。不支持blob and text

#### 4.8.3子分区
在分区的基础上再进行分区，复合分区。允许在range and list 的分区上再进行hash or key的子分区。
子分区注意问题: 1 每个子分区的数量必须相同 2 要在一个分区表的任何分区上使用subpartition来明确定义任何子分区。 3 每个子句必须包括分区的一个名字。4 子分区的名字必须是唯一的。

#### 4.8.4分区中的null值
分区总是视null值小于任何的一个非null值，这和处理null值的order by 操作是一样的。
在range分区下，null值放入最左边的分区中，如果删除p0这个分区，删除的将包含null值的记录。
在list分区下，则必须显式地指出哪个分区中放入null值，否则会报错。
hash和key分区，任何分区函数都会将含有null值的记录返回为0.

#### 4.8.5 分区和性能
对于OLAP的应用，分区确实可以很好地提高查询的性能。

然而对于OLTP的应用，分区应该非常小心。在这种应用下，通常不可能会获取一张大表中10%的数据，大部分都是通过索引返回几条记录即可，对于一张大表，一般的B+树需要2～3次的磁盘IO。因此B+树可以很好地完成操作，不需要分区的帮助，并且设计不好的分区会带来严重的性能问题。

#### 4.8.6 在表和分区间交换数据

支持alter table ... exchange partition语法。允许分区或子分区中的数据和另一个非分区的表中的数据进行交换。如果非分区表中的数据为空，那么相当于将分区中的数据移动到非分区表中，或相反。


## 第5章 索引与算法 
若索引太多，应用程序的性能可能会受到影响。而索引太少，对查询性能又会产生影响。要找到一个合适的平衡点，至关重要。


### 5.1
InnoDB支持几种常见的索引： B+树索引   全文索引    哈希索引
B+树并不能找到一个给定键值的具体行。能找到的只是被查找数据行所在的页。然后数据库通过把页读入到内存，再在内存中进行查找，最后得到要查找的数据。

### 5.2 数据结构与算法
#### 5.2.1 二分查找法
二分查找法binary search 也称为折半查找法，用来查找一组有序的记录数组中的某一记录，基本思想是：将记录按有序化（递增或递减）排列，在查找过程中采用跳跃式方式查找，即先以有序数列的中点位置为比较对象，如果要找的元素值小于该中点元素，则将待查序列缩小为左半部分，否则为右半部分。

#### 5.2.2 二叉查找树和平衡二叉树
B+树是通过二叉查找树，再由平衡二叉树B树深化而来。
在二叉查找树中左子树的键值总是小于根的键值，右子树的键值总是大于根的键值。可以通过中序遍历得到键值的排序输出。中序遍历：先查左，再查根，再查中。
平衡二叉树：首先符合二叉树查找树的定义，其次必须满足任何节点的两个子树的高度最大差为1。最好的是最优二叉树，但建立和维护成本太高，因此一般只需要建立一棵平衡二叉树即可。
平衡二叉树的维护是有一定开销的，不过多用于内存结构对象中，因此维护的开销相对较小。

### 5.3 B+树
B+树由B树和索引顺序访问方法演化而来，但是现实中几乎已经没有使用B树的情况了。
B+树：B+树是为磁盘或其他直接存取辅助设备设计的一种平衡查找树。在B+树中，所有记录节点都是按键值的大小顺序存放在同一层的叶子节点上，由各叶子节点指针进行连接。

### 5.4 B+树索引
B+树索引的本质就是B+树在数据库中的实现。因高扇出性，B+树索引的高度一般都在2-4层，查找某一键值的行记录时最多只需要2～4次

#### 5.4.1 聚集索引
聚集索引clustered index 就是按照每张表的主键构造一棵B+树，同时叶子节点中存放的即为整张表的行记录数据，也将聚集索引的叶子节点称为数据页。这个特性决定了索引组织表中的数据也是索引的一部分。同B+树数据结构一样，每个数据页都通过一个双向链表来进行链接。
数据页上存放的是完整的每行的记录，而在数据页的索引页中，存放的仅仅是键值及指向数据页的偏移量，而不是完整的行记录。
聚集索引的存储并不是物理上连续的，而是逻辑上连续的。这其中有两点：1是页通过双向链表链接，页按照主键的顺序排序；2每个页中的记录也是通过双向链表进行维护的，物理存储上可以同样不按照主键存储。

#### 5.4.2 辅助索引
辅助索引Secondary Index，叶子节点并不包含行记录的全部数据，辅助索引的书签就是相应行数据的聚集索引键。
当通过辅助索引来寻找数据时，InnoDB存储引擎会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键，然后再通过主键索引来找到一个完整的行记录。
堆表：对于其他一些数据库，如Microsoft SQL Server数据库，其有一种称为堆表的表类型，即行数据的存储按照插入的顺序存放。这与MySQL数据库的MyISAM存储引擎有些类型。堆表的特性决定了堆表上的索引都是非聚集的，主键与非主键的区别只是是否唯一且非空。
具体建堆表还是索引表，这取决于应用，不存在哪个更优的问题



#### 5.4.4 B+树索引的管理
1 索引管理
索引的创建和删除可以通过两种方法，一种是alter table add index index_name，另一种是create/drop index on tbl_name

查看表索引： show index from table;
table: 索引所在的表名
Non_unique: 非唯一的索引，primary key 是0 ，因为必须是唯一的。
Key_name: 索引的名字
Sep_in_index: 索引中该列的位置
Column_name: 索引列的名称
Collation: 列以什么方式存储在索引中。可以是A或Null。B+树索引总是A，即排序的。Heap Hash索引是null，因为不排序。
Cardinality:非常关键的值，表示索引中唯一值的数目的估计值。Cardinality/表的行数应尽可能接近1，否则要考虑是否删除索引
Sub_part：是否列的部分被索引。如果不是只对前几个字符进行索引，此值该为NULL
Packed:关键字如何被压缩。如果没有压缩，则为Null。
Null：是否索引的列含有NULL值。
Index_type:索引的类型。InnoDB存储引擎只支持B+树索引，所以这里显示的都是BTREE。
Comment：注释

Cardinality值非常关键，但并不是实时更新，即并非每次索引的更新都会更新该值，因为代价太大了。可以用ANALYZE TABLE命令。
建议在一个非高峰时间，对应用程序下的几张核心表做analyze table操作，这能使优化器和索引更好地为你工作。

2 Fast Index Creation
诟病：5.5之前，对于索引的添加或者删除这类DDL操作，过程为：1首先创建一张新的临时表，2然后把原表中数据导入到临时表 3接着删除原表。4最后把临时表重名为原来的表名。这对于大表进行索引的增改会需要很长时间。

5.5之后，Fast Index Creation 快速索引创建简称FIC
过程：1 对于辅助索引的创建，会在表上加个S锁。不需要重建表。2 删除操作，只需要更新内部视图，并将辅助索引的空间标记为可用，同时删除MySQL数据库内部视图上对该表的索引定义即可。

**由于FIC对表加上了S锁，因此只能对表进行读操作，若有大量事务需要对目标表进行写操作，那么数据库的服务同样不可用。此外FIC方式只限定于辅助索引，对于主键的创建和删除同样需要重建一张表。**

3 Online Schema Change 在线架构改变，

4 Online DDL
MySQL 5.6版本开始支持Online DDL（在线数据定义）操作，其允许辅助索引创建的同时，还允许其他诸如insert update delete 这类DML操作。
不仅是辅助索引，以下这几类DDL操作都可以通过“在线”的方式进行操作：
1辅助索引的创建与删除 2 改变自增长值 3 添加或删除外键的约束 4 列的重命名

通过新的alter table 语法，用户可以选择索引的创建方式：
alter table tbl_name
| add {index|key} [index_name]
[index_type] (index_col_name,...) [index_option]...
algorithm [=] {default|inplace|copy}
lock [=] {default|none|shared|exclusive}
具体见P209

InnoDB存储引擎实现online DDL 的原理是在执行创建或者删除操作的同时，将insert update delete这类DML操作日志写入到一个缓存中。待完成索引创建后再将重做应用到表上，以此达到数据的一致性。这个缓存的大小由参数innodb_online_alter_log_max_size控制，默认的大小为128MB。需要注意，在索引创建过程中，SQL优化器不会选择正在创建的索引。
show variables like 'innodb_online_alter_log_max_size'


### 5.5 Cardinality 值
#### 5.5.1 Cardinality
对于什么时候添加B+树索引，一般的经验是，在访问表中很少一部分时使用B+树索引才有意义。对于性别字段、地区字段、类型字段，他们的可取值的范围很小，称为低选择性。相反，如果某个字段的取值范围很广，几乎没有重复，即属于高选择性，则此时使用B+树索引是最适合的。
查看是否高选择性，可以通过show index结果中的列Cardinality来观察。Cardinality值非常关键，表示索引中不重复记录数量的预估值。在实际应用中，Cardinality/n_rows_in_table应尽可能地接近1.如果非常小，那么用户需要考虑是否还有必要创建这个索引。

#### 5.52 Innodb 存储引擎的Cardinality统计
更新Cardinality的策略：
1 表中1/16的数据已发生过变化。2 stat_modified_counter>2000 000 000，此参数表示发生变化的次数。通过采样的方式进行更新操作。

### 5.6 B+树索引的使用 
#### 5.6.1 不同应用中B+树索引的使用
OLTP：查询少量返回的数据，10条以下，这时添加B+索引才有意义
OLAT：大量分析，因此在OLAP中添加根据的应该是宏观的信息，而不是微观，例如不会对单个的姓名进行查询。但是对于OLAP中的复杂查询，要涉及多张表之间的链接操作，因此索引的添加依然是有意义的。

#### 5.6.2 联合索引
是指对表上的多个列进行索引。从本质上来说，联合索引也是一棵B+树，不同的是联合索引的键值的数量不是1，而是大于等于2.

#### 5.6.3 覆盖索引
InnoDB存储引擎支持覆盖索引（covering index，或称索引覆盖），即从辅助索引中就可以得到查询的记录，而不需要查询聚集索引中的记录。使用覆盖索引的一个好处是辅助索引不包含整行记录的所有信息，故其大小要远小于聚集索引，因此可以减少大量的IO操作。
Extra列的Using index就是代表了优化器进行了覆盖索引操作。

#### 5.6.4 优化器选择不使用索引的情况
这种情况多发生于范围查找、join链接操作、查找结果大于20%时可能会使用聚集索引，全表扫描
若用户使用的是固态硬盘，随机读操作非常快，同时有足够的自信确认使用辅助索引可以带来更好的性能，那么可强制使用索引：select * from table force index(idx_name)
顺序读要远远快于离散读。
因此对于不能进行索引覆盖的情况，优化器选择辅助索引的情况是，通过辅助索引查找的数据是少量的。

#### 5.6.5 索引提示
use index只是告诉优化器可以选择该索引，因此，如果用户确定指定某个索引来完成查询，那么最可靠的是使用FORCE INDEX，而不是USE INDEX。

#### 5.6.6 Multi-Range Read 优化
MRR优化可适用于range  ref  eq_ref类型的查询，有以下几个好处：
1 MRR使用数据访问变得较为顺序。在查询辅助索引时，首先根据得到的查询结果，按照主键进行排序，并按照主键排序的顺序进行书签查找。
2 减少缓冲池中页被替换的次数。
3 批量处理对键值的查询操作。
对于Innodb 和Myisam存储引擎的范围查询和Join查询操作，MRR的工作方式如下 ：
1 将查询得到的辅助索引键值存放于一个缓存中，这时缓存中的数据是根据辅助索键值排序的。
2 将缓存中的键值根据Rowid进行排序。
3 根据Rowid的排序顺序来访问实际数据文件。

当启动此特性后，在Extra列可以看到using MRR.  作者在笔记本上测试，启用后和不启用的执行时间相着10倍之多。
是否启用参数：  show variables like 'optimizer_switch'   mrr=on

#### 5.6.7 Index Condition Pushdown (ICP)优化
和MRR一样，5.6开始支持的一种根据索引进行查询的优化方式。之前的mysql查询时，首先根据索引来查找记录，然后再根据where条件来过滤记录。在支持ICP之后，mysql数据库会在取出索引的同时，判断是否可以进行where条件的过滤，也就是将where的部分过滤操作放在了存储引擎层。
ICP优化支持range  ref  eq_ref  ref_or_null类型的查询，当前支持Myisam 和 Innodb存储引擎。当优化器选择ICP优化时，可以在执行计划列的EXTRA看到using index condition提示。

ICP优化可以将查询效率在原有Mysql 5.5 版本的基础上提高23%。而同时启用MRR优化后，性能还能有400%的提升！

### 5.7 哈希算法
时间复杂度是一个函数：是指执行算法所需要的计算工作量。空间复杂度（所需内存空间）。
O（1）：数据增大时耗时不变；O（n）当数据增大N倍时，耗时、空增大N倍。
O（N 2平方2）当数据增大N倍时，耗时增大N的平方倍。
O（logN）当数据增大N倍（256倍），耗时增 以2为底（8倍）。
O（NlogN）当数据增大N倍（256倍），耗时增 256*8倍。

哈希算法是一种常见算法，时间复杂度为O（1），且不只存在于索引中，每个数据库应用中都存在该数据库结构。

虽然内存中查询速度很快，但是也不可能每次都要遍历所有内存来进行查找，这时对于字典操作只需O（1）的哈希算法就有了用武之地。

#### 5.7.1 哈希表
也称散列表，由直接寻址表改进而来。数据库一般采用除法散列。在哈希函数的除法散列法中，通过取K除以M的余数，将关键字K映射到M个槽的某一个去，即哈希函数：h(k) = k mod m

#### 5.7.2 Innodb存储引擎中的哈希算法
使用哈希算法来对字典进行查找，其冲突机制采用链表方式，哈希函数采用除法散列方式。
在缓冲池中的Page页都有一个chain指针，它指向相同哈希函数值的页。而对于除法散列，m的取值为略大于2倍的缓冲池页数量的质数。

#### 5.7.3 自适应哈希索引
数据库自身创建并使用的，DBA本身并不能对其进行干预。自适应哈希索引经哈希函数映射到一个哈希表中，因此对于字典类型的查找非常快速where xxx=xxx。但是对于范围查找就无能为力了。

### 5.8 全文检索
全文检索（Full-Text Search）是将存储于数据库中的整本书或整篇文章中的任意内容信息查找出来的技术。它可以根据需要获得全文中有关章、节、段、句、词等信息，也可以进行各种统计和分析。
从Innodb 1.2.x版本开始支持全文索引，其支持MyISAM存储引擎的全部功能，并且还支持其他一些特性。

#### 5.8.2 倒排索引
全文索引通常使用倒排索引（inverted index）来实现。同B+树索引一样，也是一种索引结构。它在辅助表auxiliary table中存储了单词与单词自身在一个或多个文档中所在位置之间的映射。这通常利用关联数组实现，有两种表现形式： inverted file index，其表现形式为｛单词，单词所在文档的ID｝； full inverted index，其表现形式为｛单词，（单词所在文档的ID，在具体文档中的位置）｝


#### 5.8.3 InnoDB全文索引
Innodb存储引擎从1.2X版本开始支持全文索引，其采用full inverted index 的方式。将（DocumentID，Plsition）视为一个'ilist'。因此在全文检索的表中有两个列，一个是word字段，另一个是ilist字段，并且在word字段上设有索引。
如前文所说，倒排索引需要将word存放到一张表中，这个表称为Auxiliary Table （辅助表）。在INNODB存储引擎中，为了提高全文检索的并行性能，共有6张Auxiliary Table，目前每张表根据word 的Latin编码进行分区。
Auxiliary Table 是持久的表，存放于磁盘上。用FTS index Cache（全文检索索引缓存）来提高全文索引的性能。
FTS Index Cache是一个红黑树结构，其根据（word, ilist）进行排序。类似于Insert Buffer

可以通过设置参数innodb_ft_aux_table来观察倒排索引的Auxiliary Table : set global innodb_ft_aux_table='test/fts_a';
在上述设置完成后，可以通过information_schema.innodb_ft_index_table得到表fts_a中的分词信息。
参数innodb_ft_cache_size用来控制FTS Index Cache 的大小，默认值为32M。

FTS Document ID是另外一个重要的概念。为了支持全文检索，必须有一个列与word进行映射，这个列被命名为FTS_DOC_ID，其类型必须是BIGINT UNSIGNED NOT NULL，并自动会在该列上加一个名为FTS_DOC_ID_INDEX的Unique Index，由Innodb引擎自动完成。

文档中的分词的插入操作是在事务提交时完成，然而对于删除操作，其在事务提交时，不删除磁盘Auxiliary Table中的记录，而只是删除FTS Cache Index中的记录。对于Auxiliary Table中被删除的记录，Innodb存储引擎会记录其FTS Document ID，并将其保存在DELETED auxiliary table中，设置参数innodb_ft_aux_table后，可以通过information_schema.innodb_ft_deleted来观察删除的FTS Document ID。

由于文档的DML操作实际并不删除索引的数据，相反还会在对应的DELETED表中插入记录，因此随着应用程序的允许，索引会变得非常大，即使索引中的有些数据已经被删除，查询也不会选择这类记录。**为此允许用户手工将已经删除的记录从索引中彻底删除，该命令就是OPTIMIZE TABLE**。此命令还会进行其他操作，如Cardinality 的重新统计。
如果希望仅对倒排索引进行操作，可设置参数：set global innodb_optimize_fulltext_only=1;
可通过参数限制每次实际删除的分词数量：innodb_ft_num_word_optimize   默认值为2000

create fulltext index idx_fts on fts_a(body);
5.7有新添加方法：add fulltext name(列名) with parser ngram;

通过设置参数来查看分词对应信息：innodb_ft_aux_table

stopword列表（stopword list），表示该列表中的word不需要对其进行索引分词操作。

当前全文检索还存在以下限制：
1 每张表只能有一个全文检索。
2 由多列组合而成的全文检索的索引必须使用相同的字符集与排序规则。
3 不支持没有单词界定符（delimiter）的语言，如中文、日语、韩语等。

#### 5.8.4 全文检索
Mysql数据库通过match()…against() 语法支持全文检索的查询，match指定了需要被查询的列，againxt指定了使用何种方法去进行查询。
1 Natural Language
全文检索技术使用方法：select * from fts_a where match(body) against ('Porridge' in natural language mode);
观察查询计划：可以看到type 这列显示了fulltest，即表示使用全文检索的倒排索引，而key这列显示了idx_fts，表示索引的名字

对于全文检索，还需要考虑以下的因素：
1)查询的word在stopword列中，忽略该字符串的查询。
2)查询的word的字符长度是否在区间[innodb_ft_min_token_size, innodb_ft_max_token_size]内。

2 Boolean  P243
Mysql 数据库允许使用 in boolean mode 修饰符来进行全文检索。当使用修饰符时，查询字符串的前后字符会有特殊的含义，例如下面的语句要求查询有字符串Pease 但没有hot的文档，其中+和 - 分别表示这个单词必须出现，或者一定不存在。
select * from tft_a where match(body) against ('+Pease -hot' in boolean mode) \G;

3 Query Expansion 
Mysql 数据库还支持全文检索的扩展查询。这种查询通常在查询的关键词太短，用户需要implied knowledge（隐含知识）时进行，例如对于单词database的查询，用户可能希望查询的不仅仅是包含database的文档，可能还指那些包含 Mysql Oracle db2 rdbms的单词。而这时可以使用Query Expansion 模式来开户全文检索的implied knowledge。
由于Query Expansion的全文检索可能带来许多非相关性的查询，因此在使用时，用户可能需要非常谨慎。



## 第6章 锁
开发多用户、数据库驱动的应用时，最大的一个难点是：一方面要最大程度地利用数据库的并发访问，另外一方面还要确保每个用户能以一致的方式读取和修改数据。为此就有了锁的机制，同时**这也是数据库系统区别于文件系统的一个关键特性**。InnoDB存储引擎较之Mysql数据库的其他存储引擎在这方面技高一筹，其实现方式非常类似于Oracle数据库。而只有正确了解这些锁的内部机制才能充分发挥InnoDB存储引擎在锁方面的优势。

### 6.1 什么是锁
锁是数据库系统区别于文件系统的一个关键特性。锁机制用于管理对于共享资源的并发访问。InnoDB存储引擎在**行级别上对表数据上锁**，这固然不错。不过InnoDB存储引擎**也会在数据库内部其他多个地方使用锁，从而允许对多种不同资源提供并发访问。例如，操作缓冲池中的LRU列表，删除、添加、移动LRU列表中的元素**，为了保证一致性，必须有锁的介入。数据库系统使用锁是为了支持对共享资源进行并发访问，提供数据的完整性和一致性。
另一点需要理解的是，虽然现在数据库系统做得越来越类似，但是有多少种数据库，就可能有多少种锁的实现方法。在sql语法层面，因为sql标准的存在，要熟悉多个关系数据库系统并不是一件难事。
Innodb存储引擎锁的实现和Oracle数据库非常类似，提供一致性的非锁定读、行级锁支持。行级锁没有相关额外的开销，并可以同时得到并发性和一致性。

### 6.2 lock 与 latch
这里还要区分锁中容易令人混淆的概念的lock与latch。在数据库中，lock与latch都可以被称为“锁”。但是两者有着截然不同的含义，本章主要关注的是lock。
latch 一般称为闩锁（轻量级的锁），因为其要求锁定的时间必须非常短。若持续的时间长，则应用的性能会非常差。在InnoDB存储引擎中，latch又可以分为mutex(互斥量)和rwlock（读写锁）。**其目的是用来保证并发线程操作临界资源的正确性，并且通常没有死锁检测的机制。show engine innodb mutex;**

**Lock的对象是事务，用来锁定的是数据库中的对象，如表、页、行。** 并且一般lock的对象仅在事务commit或rollback后进行释放（不同事务隔离级别释放的时间可能不同）。此外，lock，正如在大多数数据库中一样，是有死锁机制的。show engine innodb status 及 information_schema 架构下的表innodb_trx  innodb_locks  innodb_lock_waits来观察锁的信息。

### 6.3 innodb 存储引擎中的锁
innodb 存储引擎实现了如下两种标准的行级锁：
共享锁（S Lock），允许事务读一行数据。
排他锁（X Lock），允许事务删除或更新一行数据。
X锁与任何的锁都不兼容，而S锁仅和S锁兼容。需要特别注意的是S和X锁都是行锁，兼容是指对同一记录（row）锁的兼容性情况。
多粒度锁定，允许事务在行级上的锁和表级上的锁同时存在。为了支持在不同粒度上进行加锁操作，Innodb存储引擎支持一种额外的锁方式，称之为意向锁。意向锁是将锁定的对象分为多个层次，意向锁意味着事务希望在更细粒度上进行加锁。
如果需要对页上的记录R进行上X锁，那么分别需要对数据库A、表、页上意向锁IX，最后对记录R上X锁。其中任何一个部分导致等待，那么该操作需要等待粗粒度锁的完成。
意向锁即为表级别的锁。设计目的主要是为了在一个事务中揭示下一行将被请求的锁类型。支持两种意向锁：
意向共享锁（IS Lock），事务想要获得一张表中某几行的共享锁
意向排他锁（IS Lock），事务想要获得一张表中某几行的排他锁
查看锁请求信息：show engine innodb status
简单监控当前事务并分析可能存在的锁问题：在Information_schema架构下的innodb_trx  innodb_locks  innodb_lock_waits

#### 6.3.2 一致性非锁定读
通过MVCC(Multi Version Concurrency Control, MVCC)行多版本控制的方式来读取当前执行时间数据库中行的数据。如果读取的行正在执行delete  update操作，这时读取操作不会因此去等待行上的锁的释放。该实现是通过undo段来完成，而undo用来在事务中回滚数据，因此快照数据本身是没有额外的开销。这是默认的读取方式，即读取不会占用和等待表上的锁。
在事务隔离级别 read cmmitted（读行的最新一份快照数据）和repeatable read（读事务开始时的行数据版本）下，使用非锁定的一致性读。

#### 6.3.3 一致性锁定读
某些情况下，需要显示地对数据库读取操作进行加锁以保证数据逻辑的一致性。
select ... for update  --对读取的行记录加一个X锁
select ... lock in share mode    -- 对读取的行记录加一个S锁
即使加了上面两种锁，对于一致性非锁定读，也是可以进行读取的。

#### 6.3.4 自增长与锁
对于insert...select 的大数据量的插入会影响插入的性能，因为另一个事务中的插入会被阻塞。
innodb_autoinc_lock_mode
自增长值的列必须是索引，同时必须是索引的每一个列。

#### 6.3.5 外键和锁
外键主要用于引用完整性的约束检查。
对于一个外键列，会自动对其加一个索引。Oracle不会加，所以可能产生死锁。
对于外键值的插入或更新，首先需要查询父表中的记录。但是对于父表的select操作，不是使用一致性非锁定读的方式，因为这样会发生数据不一致的问题，因此这时使用的是select ...lock in share mode的方式，即主动对父表加一个S锁。

![image-20211006214058246](C:\Users\86132\AppData\Roaming\Typora\typora-user-images\image-20211006214058246.png)


### 6.4 锁的算法
#### 6.4.1 行锁的3种算法
1 Record Lock：单个行记录上的锁
2 Gap Lock：间隙锁，锁定一个范围，但不包含记录本身
3 Next-Key Lock：Gap Lock+Record Lock，锁定一个范围，并且锁定记录本身(P277)

默认为Next-key Lock，仅在查询所有的唯一索引列时会降级为Record Lock。


#### 6.4.2 解决Phantom Problem幻读
在Repeateable read 隔离级别下，采用Next-key Lock来避免Phantom Problem（幻像问题）。
而在read commited 隔离级别下，其仅采用record lock,但会导致Phantom Problem（幻像问题）

Phantom Problem（幻像问题）是指在同一事务下，连续执行两次同样的SQL语句可能导致不同的结果，第二次的SQL语句可能会返回之前不存在的行。

### 6.5 锁问题
通过锁机制可以实现事务的隔离性要求，使用事务可以并发地工作。锁提高了并发，但是却会带来潜在的问题。不过好在因为事务隔离性的要求，锁只会带来三种问题，如果可以防止这三种情况的发生，那将不会产生并发异常。

#### 6.5.1 脏读
脏页指的是在缓冲池中已经被修改的页，但是还没有刷新到磁盘中，即数据库实例内存中的页和磁盘中的页的数据是不一致的，当然在刷新到磁盘之前，日志都已经被写入到了重做日志文件中。
而所谓脏数据是指事务对缓冲池中的行记录的修改，并且还没有被提交（commit）.

脏读指的就是在不同的事务下，当前事务可以读到另外的事务未提交的数据，简单来说就是可以读到脏数据。发生的条件是隔离级别为read uncommited，所以在生产环境不常发生，一般生产至少是read commited

#### 6.5.2 不可重复读

不可重复读是指在一个事务内多次读取同一数据集合，在这个事务还没有结束时，另外一个事务也访问该同一数据集合，并做了一些DML操作。由于每二个事务的修改，那么第一个事务内两次读到的数据可能是不一样的情况，称为不可重复读。

不可重复读和脏读的区别是：脏读是读到未提交的数据，而不可重复读读到的却是已经提交的数据，但是其违反了数据库事务一致性的要求。
在Innodb中，采用Next-key Lock来避免不可重复读的问题。

在Next-key Lock算法下，对于索引的扫描，不仅是锁住扫描到的索引，而且还锁住这些索引覆盖的范围（gap）

#### 6.5.3 丢失更新
简单来说其就是一个事务的更新操作会被另一个事务的更新操作所覆盖，从而导致数据的不一致。
数据库不会产生这种情况。
但是生产应用中会存在。这是需要加个排他锁来避免这种逻辑问题的产生。select * from table where ... for update;

### 6.6 阻塞

因为不同锁之间的兼容性关系，在有些时刻一个事务中的锁需要等待另一个事务中的锁释放它所占用的资源，这就是阻塞。阻塞并不是一件坏事，其是为了确保事务可以并发且正常地运行。
innodb_lock_wait_timeout 用来控制等待的时间，默认50秒，是动态的，可以调整：set @@innodb_lock_wait_timeout=60;
innodb_rollback_on_timeout用来设定是否在等待超时时对进行中的事务进行回滚操作，默认是off，代表不回滚，静态的。
需要牢记的是，在默认情况下innodb存储引擎不会回滚超时引发的错误异常（死锁除外）。如果事务B的插入5的操作需要等待事务A释放这个资源，当等待超时抛出异常，重新查询会发现5是存在的。这是十分危险的状态，因此用户必须判断是否需要commit还是rollback，之后再进行下一步的操作。

### 6.7 死锁

死锁是指两个或两个以上的事务在执行过程中，因争夺锁资源而造成的一种互相等待的现象。
1 解决死锁问题最简单的一种方法是超时，即当两个事务互相等待时，当一个等待时间超过设置的某一阈值时，其中一个事务进行回滚，另一个等待的事务就能继续进行。参数：innodb_lock_wait_timeout用来设置超时的时间。但若超时事务所占权重比较大，回滚这个事务的时间可能会很多。

2 除了超时机制，当前数据库还都普遍采用wait-for graph等待图 的方式来进行死锁检测。这是一种更为主动的死锁检测方式。
wait-for graph 要求数据库保存以下两种信息：1 锁的信息链表 2 事务等待链表

wait-for graph 是一种较为主动的死锁检测机制，在每个事务请求锁并发生等待时都会判断是否存在回路，若存在则有死锁，通常来说innodb存储引擎选择回滚undo量最小的事务。

#### 6.7.2 死锁概率
死锁应该非常少发生，若经常发生，则系统是不可用的。此外，死锁的次数应该还要少于等待，因为至少两次等待才会产生一次死锁。


#### 6.7.3 死锁的示例
Innodb 存储引擎并不会回滚大部分的错误异常，但是死锁除外。
1213：死锁  1205：锁等待超时

### 6.8 锁升级
Innodb 存储引擎不存在锁升级的问题。因为其不是根据每个记录来产生行锁的，相反，其根据每个事务访问的每个页对锁进行管理，采用的是位图的方式。因此不管一个事务锁住页中一个记录还是多个记录，其开销通常都是一致的。

### 6.9 小结：
用户需要理解锁来来的问题，如丢失更新、脏读、不可重复读等。


## 第7章 事务

事务Transaction是数据库区别于文件系统的重要特性之一。事务会把数据库从一种一致状态转换为另一种一致状态。
在Innodb存储引擎中的事务完全符合ACID的特性。
原子性 atomicity
一致性 consistency
隔离性 isolation
持久性 durability

上1（6）章介绍了锁，讨论Innodb是如何实现事务的隔离性。本章主要关注事务的原子性：

### 7.1 认识事务
#### 7.1.1 概述
事务是访问并更新数据库中各种数据项的一个程序执行单元。在事务中的操作，要么都做修改，要么都不做，这就是事务的目的，也是事务模型区别与文件系统的重要特征之一。
原子性：指整个数据库事务是不可分割的工作单位。
一致性：事务将数据库从一种状态转变为下一种致性的状态。在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。
隔离性：隔离性还有其他的称呼，如并发控制、可串行化、锁等。事务的隔离性要求每个读写事务的对象对其他事务的操作对象能相互分离，即该事务提交前对其他事务不可见，通常这种使用锁来实现。
持久性：事务一旦提交，其结果就是永久性的。即使发生宕机等故障，数据也能将数据恢复。因此持久性保证事务系统的高可靠性，而不是高可用性。对于高可用性的实现，事务本身并不能保证，需要一些系统共同配合来完成。

#### 7.1.2 分类
从事务理论的角度来说，可以把事务分为以下几种类型：
1 扁平事务
2 带有保存点的扁平事务
3 链事务
4 嵌套事务
5 分布式事务

### 7.2 事务的实现
**事务的隔离性由锁来实现。原子性、一致性、持久性通过数据库的redo log 和 undo log来完成**。redo log称为重做日志，用来保证事务的原子性和持久性。undo log 用来保证事务的一致性。
有的DBA或许会认为undo是redo的逆过程，其实不实。redo和undo的作用都可以视为是一种恢复操作，redo恢复提交事务修改的页操作，而undo回滚行记录到某个特定版本。因此两者记录的内容不同，redo通常是物理日志，记录的是页的物理修改操作。undo是逻辑日志，根据每行记录进行记录。

#### 7.2.1 redo

##### 1基本概念
重做日志由两部分组成：一是内存中的重做日志缓冲，其是易失的；二是重做日志文件（redo log file），其是持久的。
其通过Force Log at Commit机制实现事务的持久性，即当事务提交时，必须先将该事务的所有日志写入到重做日志文件进行持久化，待事务的COMMIT操作完成才算完成。这里的日志是指重做日志，在Innodb存储引擎中，由两部分组成，即redo log 和 undo log。redo log 用来保证事务的持久性，undo log 用来帮助事务回滚及MVCC的功能。redo log是顺序写的，在数据库运行时不需要对redo log 的文件进行读取操作，而undo log 是需要进行随机读写的。
为了确保每次日志都写入重做日志文件，在每次将重做日志缓冲写入重做日志文件后，**innodb存储引擎都需要调用一次fsync操作**。

##### 2 log block
重做日志都是以512字节进行存储的。这意味着重做日志缓存、重做日志文件都是以块的方式进行保存的，称之为重做日志块，每块的大小为512字节。**由于重做日志块的大小和磁盘扇区的大小一样，都是512字节，因此重做日志的写入可以保证原子性，不需要doublewrite技术**。
日志块由三部分组成，依次为日志块头12字节，日志内容492字节，日志块尾8字节。

##### 3 log group

重做日志组，由多个重做日志文件组成。是一个逻辑上的概念，其存储的就是之前的log buffer中保存的log block，因此其也是根据块的方式进行物理存储的管理，每个块的大小与log block 一样，同样为512字节。
log buffer根据一定的规则将内存中的log block 刷新到磁盘。这个规则具体是：
1 事务提交时
2 当log buffer中有一半的内存空间已经被使用时
3 log checkpoint 时

##### 4 重做日志格式
##### 5 LSN
Log Sequence Number的缩写，其代表的是日志序列号。含义有1重做日志的总量。2 checkpoint的位置。3 页的版本。
LSN不仅记录在重做日志中，还存在于每个页中。

##### 6 恢复
Innodb 存储引擎的重做日志是物理日志，因此其恢复速度较之二进制日志恢复快得多。

#### 7.2.2 undo
##### 1 基本概念
redo 存放在重做日志文件中，与redo不同，undo存放在数据库内部的一个特殊段中，这个段称为undo段。**undo段位于共享表空间内。**
除了回滚操作，undo的另一个作用是MVCC，即在innodb存储引擎中的MVCC的实现是通过UNDO来完成的。

##### 2 UNDO存储管理
innodb存储引擎对undo的管理同样采用段的方式。但是这个段和之前介绍的段有所不同。可以重用
可以通过命令show engine innodb status来查看链表中的undo log的数量：history list lengh 就代表了undo log的数量

##### 3 undo log 格式
undo log 分为：
insert undo log:是指在insert操作中产生的undo log      
update undo log:是对delete和upudate操作产生的undo log.该undo log可能需要提供MVCC机制，因此不能在事务提交时就进行删除。提交时放入undo log链表，等待purge线程进行最后的删除。

#### 7.2.3 purge
delete update操作可能并不直接删除原有的数据。purge用于最终完成delete update操作。这样设计是因为innodb存储引擎支持MVCC，所以记录不能在事务提交时立即进行处理。
purge操作是清理之前的delete update操作，并将上述操作最终完成。

全局动态参数innodb_purge_batch_size用来设置每次purge操作需要清理的undo page 数量。
全局动态参数innodb_max_purge_lag用来控制history list的长度，若长度大于该参数时，其会延缓DML的操作。该参数默认为0,表示不对history list做任何限制。

### 7.3 事务控制语句
start transaction | begin
commit
rollback
savepoint identifier：创建一个保存点
release savepoint identifier：删除一个事务的保存点，
rollback to [savepoint] identifier：把事务回滚到标记点
set transaction: 设置事务的隔离级别
在存储过程中只能使用start transaction 语句来开户一个事务。

### 7.4 隐式提交的sql语句
DDL语句：alter database ... update data idrectory name, alter event,alter procedure,alter table, alter view.create..drop..rename..truncate table
修改mysql架构的操作：create user\drop user \grant\rename user\revoke\set password
管理语句：analyze table\ vreate index\check table\load index into cache\optimize \table repair table...


### 7.5 对于事务操作的统计
不会计算隐式提交的事务
show global status like 'com_commit'\G

### 7.6 事务的隔离级别
默认为repeatable read
在serialiable的事务隔离级别，会对每个select自动加上LOCK IN SHARE MODE,即为每个读取操作加一个共享锁。读占用了锁，对一致性非锁定读不再予以支持。

### 7.7 分布式事务
#### 7.7.1 mysql 数据库分布式事务
分布式事务指的是允许多个独立的事务资源参与到一个全局的事务中。事务资源通常是关系型数据库系统，但也可以是其他类型的资源。全局事务要求在其中的所有参与的事务要么都提交，要么都回滚，这对于事务原有的ACID要求又有了提高。另外，在使用分布式事务时，Innodb存储引擎的事务隔离级别必须设置为SERIALIZABLE。
分布式事务可能在银行系统的转账中比较常见。

XA事务由一个或多个资源管理器、一个事务管理器以及一个应用程序组成。
资源管理器：提供访问事务资源的方法。通常一个数据库就是一个资源管理器。
事务管理器：协调参与全局事务中的各个事务。需要和参与全局事务的所有资源管理器进行通信。
应用程序：定义事务的边界，指定全局事务中的操作。

分布式事务使用两段式提交的方式。在第一阶段，所有参与全局事务的节点都开始准备prepare，告诉事务管理器它们准备好提交了。第二阶段，事务管理器告诉资源管理器执行rollback还是commit。如果任何一个节点显示不能提供，则所有的节点都被告知需要回滚。

#### 7.7.2内部XA事务
最为常见的内部XA事务存在于binlog与innodb存储引擎之间。由于复制的需要，因此目前绝大多数的数据库都开启了binlog功能，在事务提交时，先写二进制日志，再写innodb存储引擎的重做日志。对于上述两个操作的要求也是原子的，即二进制日志和重做日志必须同时写入。否则若发生了宕机，会导致主从不一致的情况。
Mysql数据库在binlog 与innodb存储引擎之间采用了XA事务。当事务提交时，innodb存储引擎会先做个prepare操作，将事务的Xid写入，接着进行二进制日志的写入，如果在innodb存储引擎提交前，Mysql数据库宕机了，那么Mysql数据库在重启后会先检查准备的UXID事务是否已经提交，若没有，则在存储引擎再进行一次提交操作。

### 7.8 不好的事务习惯
1 在循环中提交：在存储过程中，不应该在一个循环中反复进行提交操作，不论是显式的提交还是隐式的提交。
2 使用自动提交：并不是一个好习惯，因为这会使初级DBA容易犯错。
3 使用自动回滚：无法得到错误信息。因此最好用程度控制事务。

### 7.9 长事务
就是执行时间较长的事务。有时可以通过转化为小批量的事务来进行处理。


## 第8章 备份与恢复

### 8.1 备份与恢复概述
根据备份的方法不同分为：
Hot Back 热备：指在数据库运行中直接备份，对于正在运行的数据库操作没有任何影响（在线备份）。
Cold Backup 冷备：最为简单，一般只需要复制相关的数据库物理文件即可。（离线备份）
Warm Backup 温备：同样在数据库运行中进行，但是会对当前数据库的操作有所影响，如加一个全局读锁以保证备份数据的一致性。

按照备份后文件的内容，又可分为：
逻辑备份：指备份出的文件是可读的，一般是文本文件。内容一般是由sql语句，或者表内实现数据组成。如mysqldump和select * into outfile的方法。这类文件的好处是可以观察导出文件的内容，一般适用于数据库的升级、迁移等工作。缺点是恢复时间较长。
裸文件备份：是指复制数据库的物理文件，既可以是在数据库运行中的复制（如ibbackupu、xtrabackup这类工具），也可以是在数据库停止运行时直接的数据文件手复制。这类备份的恢复时间往往较逻辑备份短很多。

按照备份数据库的内容来分：
完全备份：对数据库进行一个完整的备份。
增量备份：在上次完全备份的基础上，对于更新的数据库进行备份。
日志备份：主要是指对二进制日志的备份，通过对一个完全备份进行二进制日志的重做replay来完成数据库的point-in-time的恢复工作。

mysql数据库复制的原理就是异步实时地将二进制日志重做传送并应用到从数据库。

### 8.2 冷备
对于Innodb存储引擎的冷备非常简单，只需要备份Mysql数据库的frm文件，共享表空间文件，独立表空间文件*.ibd，重做日志文件。另外建议定期备份mysql数据库的配置文件my.cnf，这样有利于恢复的操作。

冷备的优点是：
1 备份简单，只要复制相关文件即可。
2 备份文件易于在不同操作系统，不同Mysql版本上进行恢复。
3 恢复相当简单，只需要把文件恢复到指定位置即可。
4 恢复速度快，不需要执行任何SQL语句，也不需要重建索引。
冷备的缺点是：
1 Innodb存储引擎准备的文件通常比逻辑文件大很多，因为表空间中存放着很多其他数据，如undo段，插入缓冲等信息。
2 冷备也不总是可以轻易地跨平台。操作系统、Mysql的版本、文件大小写敏感和浮点数格式都会成为问题。

### 8.3 逻辑备份

#### 8.3.1 mysqldump
mysqldump [arguments] > file_name
备份所有数据库：
mysqldump --all-databases > dump.sql
指定数据库：
mysqldump --databases db1 db2 db3 > dump.sql
对test这个架构进行备份，可以：
mysqldump --single-transaction tet > test_backup.sql

比较重要的参数
--single-transaction: 在备份开始前，先执行start transaction命令，以此来获得备份的一致性，只对innodb存储引擎有效，确保没有其他任何DDL语句执行，因为一致性读并不能隔离DDL操作。

--lock-tables (-l):在备份中，依次锁住每个架构下的所有表。**一般用于MYISAM存储引擎**，INNODB不需要此参数，用--single-transaction即可,此两个参数互斥，不能同时使用。

--lock-all-tables:对所有架构中的所有表上锁。

--add-drop-database: 在create database前先运行drop database。要和--all-databases或者 --databases选项一起使用。在默认情况下不会有create database，除非指定这个参数。

--master-data[=value]：当值为1 时，转存文件中记录change master语句。为2时，change master语句被写出sql注释。默认为空。

--master-data 会自动忽略--lock-tables选项。如果没有使用--single-transaction 选项，则会自动使用--lock-all-tables选项。

--events(-E)：备份事件调度器。

--routines(-R):备份存储过程和函数。

--triggers: 备份触发器。

--hex-blob:将binary\varbinary\blog和BIT列类型备份为十六进制的格式 。

--tab=path(-T path)：产生tab 分割的数据文件。对于每张表，mysqldump创建一个包含create table 语句的table_name.sql文件，和包含数据的tbl_name.txt文件。可以使用--fields-terminated-by=...  --fields-enclosed-by=... fileds-optionaly-enclosed-by=... fields-escaped-by=... --lines-terminated-by=... 来改变默认的分割符、换行符。

--where='where_condition' (-w 'where_condition')：导出给定条件的数据。如导出b架构下的表a,并且表a的数据大于2：
mysqldump --single-transaction --where='b>2' test a > a.sql


#### 8.3.2 select ... into outfile
文件所在的路径的权限必须是mysql:mysql，否则会报没有权限导出

select column1 ,comumn2 ...
into 
outfile 'file_name'

fields 
terminated by 'string' 表示每个列的分隔符，默认：'\t'
optionaly enclosed by 'char' 表示对于字符串的包含符，默认：''
escaped by 'char' 表示转义符 ，默认：'\\'

 lines
starting by 'string' 表示每行的开始符号，默认：'\n'
terminated by 'string' 表示每行的结束符号，默认：''

from table where ...

#### 8.3.3 逻辑备份的恢复

mysql -uroot -p < test_backup.sql

source /home/mysql/test_backup.sql

注意无法导出视图，需要单独导出视力的定义在恢复时进行导入。

#### 8.3.4 load data infile
使用load data infile,必须拥有file权。和select into outfile命令完全一样。
ignore number lines选项可以忽略导入的前几行。

#### 8.3.5 mysqlimport
大多数选项都和load data infile语法相同。
mysqlimport [options] db_name textfile1 [textfile2 ... ]

### 8.4 二进制日志备份与恢复
在配置文件中启用二进制文件：

推荐设置：
[mysqld]
log-bin=mysql-bin
sync_binlog=1
innodb_support_xa=1

flush logs:命令可以生成一个新的二进制日志文件，然后备份之前的二进制日志。

恢复：mysqlbinlog [options] log_file...

例如要还原binlog.0000001,可以使用以下命令：
mysqlbinlog binlog.0000001 ｜ mysql -uroot -p test

对于多个二进制日志文件，要同时恢复：
mysqlbinlog binlog.[0-10]* | mysql -u root -p test

也可以通过mysqlbinlog命令导出到一个文件，然后再通过source命令来导入：
shell>mysqlbinlog binlog.0000001 > /tmp/statements.sql
shell>mysqlbinlog binlog.0000002 >> /tmp/statements.sql
shell>mysql -u root -p -e "sorce /tmp/statements.sql"

--start-position 和 --stop-position选项可以用来指定从二进制日志的某个偏移量来进行恢复，这样可以跳过某些不正确的语句：
shell>mysqlbinlog --start-position=1097856 binlog.0000001 | mysql -uroot -ptest

### 8.5 热备
#### 8.5.1 ibbackup
innodb存储引擎官方提供的热备工具，可以同时备份MyIsAM和InnoDB表，对于 InnoDB存储引擎表其备份工作原理如下：
1 记录备份开始时，InnoDB存储引擎重做日志文件检查点LSN。
2 复制共享表空间文件以及独立表空间文件。
3 记录复制完表空间文件后，InnoDB重做日志文件检查点的LSN。
4 复制在备份时产生的重做日志。
在备份期间不会对数据库本身有任何影响，所做的操作只是复制数据库文件，因此任何对数据库的操作都是允许的，不会阻塞任何操作。
ibbackup的优点如下：
-在线备份，不阻塞任何的sql语句
-备份性能好，备份的实质是复制数据库文件和重做日志文件。
-支持压缩备份，通过选项，可以支持不同级别的压缩
-跨平台支持，ibbackup可以运行在linux windows以及主流的unix系统平台上。
ibbackup对innodb存储引擎表的恢复步骤为：
-恢复表空间文件
-应用重做日志文件。

ibbackup是收费的，percona公司带来了开源、免费的XtraBackup热备工具，它实现所有ibbackup的功能，并且扩展支持了真正的增量备份功能。因此更好的选择是使用XtraBackup来完成热备的工作。

#### 8.5.2 XtraBackup
使用方法如下：
xtrabackup--backup | prepare [optins]

#### 8.5.3 XtraBackup 实现增量备份
XtraBackup工具支持对于Innodb存储引擎的增量备份，工作原理：
1 首先完成一个全备，并记录下此时检查点的LSN。
2 在进行增量备份时，比较表空间中每个页的LSN是否大于上次备份时的LSN，如果是，则备份该页，同时记录当前检查点的LSN。

### 8.5 快照备份（P372）
Mysql 数据库本身并不支持快照功能，因此快照备份是指通过文件系统支持的快照功能对数据库进行备份。
LVM（Logical Volume Manager,LVM）是LINUX系统下对磁盘分区进行管理的一种机制。LVM在硬盘和分区上建立一个逻辑层，来提高磁盘分区管理的灵活性。管理员可以通过LVM系统轻松管理磁盘分区
vgdisplay
lvdisplay

### 8.7 复制
####8.7.1 复制的工作原理
复制是Mysql数据库提供的一种高可用高性能的解决方案，一般用来建立大型的应用。3个步骤：
1 主服务器把数据更改记录到二进制日志binlog中
2 从服务器把主服务器的二进制日志复制到自己的中继日志relay log中
3 从服务器重做中继日志中的日志，把更改应用到自己的数据库上，以达到数据的最终一致性。
复制的工作原理并不复杂，已经一个完全备份加上二进制日志备份的还原。不是完全的实时同步，而是异步实时。

#### 8.7.2 快照+复制的备份架构
复制可以用来做为备份，但功能不仅限于备份，其主要功能如下：
-数据分布。可以在不同的数据中心之间实现数据的复制。
-读取的负责平衡。
-数据库备份。复制对备份很有帮助，但是从服务器不是备份，不能完全代替备份。
-高可用性和故障转移。有助于故障转移，减少故障的停机时间和恢复时间。

如果在主库执行了如drop database或drop table等操作，这时用户怎样从服务器进行恢复呢？因此，一个比较好的方法是通过对从服务器上的数据库所在分区做快照，以此来避免误操作对复制造成的影响。当发生主服务器上的误操作时，只需要将从服务器上的快照进行恢复，然后再根据二进制日志进行point-in-time的恢复即可。
延时复制很难精准地控制，也起不到对误操作的防范作用。


## 第09章 性能调优
本章将从以下几个方面集中讲解innodb存储引擎的性能问题：
选择合适的CPU
内存的重要性
硬盘对数据库性能的影响
合理地设置RAID
操作系统的选择也很重要
不同文件系统对数据库的影响
选择合适的基准测试工具

### 9.1 选择合适的CPU
若用户的CPU支持多核，可通过修改参数innodb_read_io_theads和innodb_write_io_threads来增大IO的线程，更充分有效地利用CPU的多核性能。

### 9.2 内存的重要性
内存的大小是最能直接反映数据库的性能，innodb存储引擎即缓存数据，又缓存索引，并且将他们缓存于一个很大的缓冲池中，即innodb_buffer_pool。因此，内存的大小直接影响了数据库的性能。

### 9.3 硬盘对于数据库性能的影响

## 第10章 InnoDB存储引擎源代码的编译和调试







## 8-3 MySQL参数优化

![image-20211007234658732](C:\Users\86132\AppData\Roaming\Typora\typora-user-images\image-20211007234658732.png)

show VARIABLES like 'MAX_CONNECTION%';
show VARIABLES like 'MAX_u%';
show STATUS like 'MAX_u%';

set GLOBAL max_connections=300;



![image-20211007235508181](C:\Users\86132\AppData\Roaming\Typora\typora-user-images\image-20211007235508181.png)

show VARIABLES like 'back_log%';



![image-20211007235843009](C:\Users\86132\AppData\Roaming\Typora\typora-user-images\image-20211007235843009.png)



show VARIABLES like 'innodb_thread_concurrency%';
set GLOBAL innodb_thread_concurrency=2;    -- cpu核心的2倍





![image-20211008000039996](C:\Users\86132\AppData\Roaming\Typora\typora-user-images\image-20211008000039996.png)

show VARIABLES like 'wait_timeout%';
set GLOBAL wait_timeout=3600;  -- 设置为1小时，默认为8小时



![image-20211008000338903](C:\Users\86132\AppData\Roaming\Typora\typora-user-images\image-20211008000338903.png)



show VARIABLES like 'innodb_buffer_pool_size%';    134217728 / 1024 / 1024 = 128M



